---
title: "Portfolio Optimization with Multivariate GARCH Model Comparison"
author: Martin Hoshi Vognsen
header-includes:
   - \usepackage[default]{sourcesanspro}
   - \usepackage[T1]{fontenc}
   - \usepackage[fontsize=8pt]{scrextend}
mainfont: SourceSansPro
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    code_folding: show
    theme: flatly
date: "`r format(Sys.time(), '%H:%M %d %B %Y')`"
vignette: >
  %\VignetteIndexEntry{Portfolio Optimization with Multivariate GARCH Model Comparison}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.height = 6,
  cache = FALSE
)
```

```{r load_packages, message=FALSE}
library(tsbs)
library(quantmod)
library(ggplot2)
library(gridExtra)
```

```{r global_settings}
## =============================================================================
## GLOBAL SETTINGS - Adjust these to control computation time and data source
## =============================================================================

## Set to TRUE for full analysis, FALSE for quick demo
FULL_ANALYSIS <- FALSE

## Data source: "package" uses pre-downloaded data from tsbs package
##              "download" fetches fresh data from Yahoo Finance
DATA_SOURCE <- "package"  ## Options: "package" or "download"

if (FULL_ANALYSIS) {
  max_num_rb <- 10      ## Number of rebalances with bootstrap
  max_iter <- 20        ## Maximum EM iterations per model
  num_boots <- 100         ## Bootstrap replicates per rebalance
  train_window <- 504   ## ~2 years training
} else {
  max_num_rb <- 3       ## Quick demo: 3 rebalances
  max_iter <- 3         ## Quick demo: 3 iterations
  num_boots <- 30          ## Quick demo: 30 replicates
  train_window <- 252   ## Quick demo: 1 year training
}

collect_diagnostics <- TRUE
verbose <- FALSE
return_fit <- TRUE
```

# Introduction

This vignette demonstrates advanced portfolio optimization using the **tsbs** package's Markov-Switching VARMA-GARCH bootstrap framework. We compare three multivariate GARCH correlation structures:

1. **DCC (Dynamic Conditional Correlation)**: The workhorse model with explicit correlation dynamics
2. **CGARCH (Copula GARCH)**: Separates marginals from dependence via copula theory
3. **GOGARCH (Generalized Orthogonal GARCH)**: Uses ICA to extract independent factors

Each model captures time-varying correlations differently, leading to potentially different portfolio allocations and uncertainty quantification.

## Key Features Demonstrated

- Six portfolio optimization strategies with real market data
- Out-of-sample backtesting with quarterly rebalancing
- **Bootstrap uncertainty quantification** comparing all three GARCH models
- **Bootstrap diagnostics** using the `tsbs_diagnostics` system
- Comprehensive performance analysis with transaction costs

## What is a Bootstrapped Series?

Before diving into portfolio optimization, let's visualize what the MS-VARMA-GARCH bootstrap actually produces. The basic idea is:

1. Take raw price data and compute log-returns
2. Fit a Markov-Switching model that identifies different market regimes (e.g., calm vs. volatile periods)
3. Generate new return series by resampling blocks of returns while respecting the regime structure
4. Convert the bootstrapped returns back to a synthetic price series

The plot below shows an original SPY price series alongside a bootstrapped version. The colored bands indicate the estimated market regimes—notice how the bootstrap preserves the general character of each regime while creating a genuinely new path.

```{r bootstrap_illustration, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=8}
## =============================================================================
## BOOTSTRAP ILLUSTRATION - Visual demonstration of what a bootstrap series is
## =============================================================================

## Try to use package data first, then fall back to download
spy_prices <- NULL
spy_returns <- NULL

if (DATA_SOURCE == "package") {
  ## Use package price data
  tryCatch({
    data("etf_prices", package = "tsbs")
    spy_prices <- etf_prices[, "SPY"]
    spy_returns <- diff(log(spy_prices)) * 100
    spy_dates <- attr(etf_prices, "dates")[-1]
  }, error = function(e) NULL)
}

if (is.null(spy_prices)) {
  ## Fall back to downloading
  spy_data <- tryCatch({
    getSymbols("SPY", src = "yahoo", from = "2020-01-01", to = "2023-12-31", 
               auto.assign = FALSE)
  }, error = function(e) NULL)
  
  if (!is.null(spy_data)) {
    spy_prices <- as.numeric(Ad(spy_data))
    spy_returns <- diff(log(spy_prices)) * 100
    spy_dates <- index(spy_data)[-1]
  }
}

if (!is.null(spy_returns)) {
  n <- length(spy_returns)
  
  ## Fit a simple 2-state model to get regime classification
  ## We'll use a basic approach: classify by rolling volatility
  roll_vol <- function(x, window = 21) {
    result <- rep(NA, length(x))
    for (i in window:length(x)) {
      result[i] <- sd(x[(i - window + 1):i])
    }
    result
  }
  
  vol_series <- roll_vol(spy_returns, 21)
  vol_median <- median(vol_series, na.rm = TRUE)
  
  ## Classify regimes: 1 = low volatility, 2 = high volatility
  regimes <- ifelse(vol_series > vol_median, 2, 1)
  regimes[is.na(regimes)] <- 1
  
  ## Generate a bootstrap series using regime-based block resampling
  set.seed(123)
  
  ## Identify regime blocks
  rle_regimes <- rle(regimes)
  block_ends <- cumsum(rle_regimes$lengths)
  block_starts <- c(1, head(block_ends, -1) + 1)
  block_states <- rle_regimes$values
  
  ## Sample blocks to create bootstrap series
  boot_returns <- numeric(0)
  boot_regimes <- numeric(0)
  target_length <- n
  
  while (length(boot_returns) < target_length) {
    ## Sample a random block
    block_idx <- sample(length(block_starts), 1)
    block_ret <- spy_returns[block_starts[block_idx]:block_ends[block_idx]]
    block_reg <- rep(block_states[block_idx], length(block_ret))
    
    boot_returns <- c(boot_returns, block_ret)
    boot_regimes <- c(boot_regimes, block_reg)
  }
  
  ## Trim to exact length
  boot_returns <- boot_returns[1:target_length]
  boot_regimes <- boot_regimes[1:target_length]
  
  ## Convert bootstrap returns to prices (starting from same initial price)
  initial_price <- spy_prices[1]
  boot_prices <- initial_price * exp(cumsum(boot_returns / 100))
  orig_prices <- spy_prices[-1]  # Remove first price (no return for it)
  
  ## Create plot data
  plot_df <- data.frame(
    Day = rep(1:n, 2),
    Price = c(orig_prices, boot_prices),
    Type = rep(c("Original SPY", "Bootstrap Series"), each = n),
    Regime = c(regimes, boot_regimes)
  )
  
  ## Create regime background data for shading
  create_regime_bands <- function(regimes, type_label) {
    rle_reg <- rle(regimes)
    ends <- cumsum(rle_reg$lengths)
    starts <- c(1, head(ends, -1) + 1)
    
    data.frame(
      xmin = starts,
      xmax = ends,
      Regime = rle_reg$values,
      Type = type_label
    )
  }
  
  regime_bands <- rbind(
    create_regime_bands(regimes, "Original SPY"),
    create_regime_bands(boot_regimes, "Bootstrap Series")
  )
  regime_bands$Regime_Label <- ifelse(regime_bands$Regime == 1, 
                                       "Low Volatility", "High Volatility")
  
  ## Plot
  p <- ggplot() +
    ## Regime shading
    geom_rect(data = regime_bands,
              aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf, 
                  fill = Regime_Label),
              alpha = 0.2) +
    ## Price lines
    geom_line(data = plot_df, 
              aes(x = Day, y = Price, color = Type),
              linewidth = 0.5) +
    ## Facet by series type
    facet_wrap(~ Type, ncol = 1, scales = "free_y") +
    ## Styling
    scale_fill_manual(values = c("Low Volatility" = "lightblue", 
                                  "High Volatility" = "salmon"),
                      name = "Market Regime") +
    scale_color_manual(values = c("Original SPY" = "darkblue", 
                                   "Bootstrap Series" = "darkred"),
                       guide = "none") +
    labs(title = "Original vs. Bootstrapped Price Series",
         subtitle = "Bootstrap preserves regime structure while generating a new price path",
         x = "Trading Days",
         y = "Price ($)") +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      strip.text = element_text(face = "bold", size = 11),
      plot.title = element_text(face = "bold"),
      panel.grid.minor = element_blank()
    )
  
  print(p)
  
} else {
  cat("Could not load SPY data for illustration.\n")
}
```

The bootstrap series (bottom panel) is not a forecast—it's a *plausible alternative history* that could have occurred given the same underlying market dynamics. By generating many such series and computing portfolio weights on each, we can quantify how uncertain our optimal allocation really is.

# Part 1: Portfolio Optimization Functions

```{r portfolio_functions}
## =============================================================================
## PORTFOLIO OPTIMIZATION FUNCTIONS
## =============================================================================

## 1.1 Minimum Variance Portfolio
min_variance_portfolio <- function(returns, ...) {
  Sigma <- cov(returns)
  n <- ncol(returns)
  
  if (requireNamespace("quadprog", quietly = TRUE)) {
    Dmat <- 2 * Sigma + diag(1e-8, n)
    dvec <- rep(0, n)
    Amat <- cbind(rep(1, n), diag(n))
    bvec <- c(1, rep(0, n))
    sol <- tryCatch(
      quadprog::solve.QP(Dmat, dvec, Amat, bvec, meq = 1),
      error = function(e) NULL
    )
    if (!is.null(sol)) {
      weights <- pmax(sol$solution, 0)
      weights <- weights / sum(weights)
    } else {
      weights <- rep(1/n, n)
    }
  } else {
    ones <- rep(1, n)
    Sigma_inv <- tryCatch(solve(Sigma + diag(1e-6, n)), 
                          error = function(e) diag(1/diag(Sigma)))
    weights <- as.vector(Sigma_inv %*% ones) / as.vector(t(ones) %*% Sigma_inv %*% ones)
    weights <- pmax(weights, 0)
    weights <- weights / sum(weights)
  }
  names(weights) <- colnames(returns)
  weights
}

## 1.2 Maximum Sharpe Ratio Portfolio
max_sharpe_portfolio <- function(returns, rf = 0, ...) {
  mu <- colMeans(returns)
  Sigma <- cov(returns)
  n <- ncol(returns)
  mu_excess <- mu - rf
  
  if (all(mu_excess <= 0)) {
    return(min_variance_portfolio(returns))
  }
  
  if (requireNamespace("quadprog", quietly = TRUE)) {
    Dmat <- 2 * Sigma + diag(1e-8, n)
    dvec <- rep(0, n)
    Amat <- cbind(mu_excess, diag(n))
    bvec <- c(1, rep(0, n))
    sol <- tryCatch(
      quadprog::solve.QP(Dmat, dvec, Amat, bvec, meq = 1),
      error = function(e) NULL
    )
    if (!is.null(sol) && sum(sol$solution) > 0) {
      weights <- pmax(sol$solution, 0)
      weights <- weights / sum(weights)
    } else {
      weights <- min_variance_portfolio(returns)
    }
  } else {
    weights <- min_variance_portfolio(returns)
  }
  names(weights) <- colnames(returns)
  weights
}

## 1.3 Risk Parity Portfolio
risk_parity_portfolio <- function(returns, ...) {
  Sigma <- cov(returns)
  n <- ncol(returns)
  
  vols <- sqrt(diag(Sigma))
  if (any(!is.finite(vols)) || any(vols < 1e-10)) {
    weights <- rep(1/n, n)
    names(weights) <- colnames(returns)
    return(weights)
  }
  
  weights <- 1 / vols
  weights <- weights / sum(weights)
  
  for (iter in 1:20) {
    port_vol <- sqrt(t(weights) %*% Sigma %*% weights)
    if (!is.finite(port_vol) || port_vol < 1e-10) break
    
    mrc <- (Sigma %*% weights) / as.numeric(port_vol)
    rc <- weights * mrc
    target_rc <- sum(rc) / n
    adjustment <- target_rc / (rc + 1e-8)
    weights <- weights * sqrt(pmax(adjustment, 0))
    
    if (sum(weights) < 1e-10 || any(!is.finite(weights))) {
      weights <- rep(1/n, n)
      break
    }
    weights <- weights / sum(weights)
  }
  
  names(weights) <- colnames(returns)
  weights
}

## 1.4 Black-Litterman Portfolio
black_litterman_portfolio <- function(returns, risk_aversion = 2.5, tau = 0.05, ...) {
  mu_hist <- colMeans(returns)
  Sigma <- cov(returns)
  n <- ncol(returns)
  
  w_mkt <- rep(1/n, n)
  pi <- risk_aversion * Sigma %*% w_mkt
  
  P <- diag(n)
  Q <- mu_hist
  omega_diag <- diag(Sigma) * tau
  Omega <- diag(omega_diag)
  
  tau_Sigma <- tau * Sigma
  tau_Sigma_inv <- solve(tau_Sigma + diag(1e-8, n))
  Omega_inv <- solve(Omega + diag(1e-8, n))
  
  M_inv <- tau_Sigma_inv + t(P) %*% Omega_inv %*% P
  M <- solve(M_inv + diag(1e-8, n))
  mu_bl <- M %*% (tau_Sigma_inv %*% pi + t(P) %*% Omega_inv %*% Q)
  
  if (requireNamespace("quadprog", quietly = TRUE)) {
    Sigma_bl <- Sigma + tau_Sigma
    Dmat <- 2 * risk_aversion * Sigma_bl + diag(1e-8, n)
    dvec <- as.vector(mu_bl)
    Amat <- cbind(rep(1, n), diag(n))
    bvec <- c(1, rep(0, n))
    sol <- tryCatch(
      quadprog::solve.QP(Dmat, dvec, Amat, bvec, meq = 1),
      error = function(e) NULL
    )
    if (!is.null(sol)) {
      weights <- pmax(sol$solution, 0)
      weights <- weights / sum(weights)
    } else {
      weights <- rep(1/n, n)
    }
  } else {
    weights <- rep(1/n, n)
  }
  names(weights) <- colnames(returns)
  weights
}

## 1.5 Mean-Variance with Shrinkage (Ledoit-Wolf)
shrinkage_portfolio <- function(returns, target_return = NULL, ...) {
  mu <- colMeans(returns)
  n <- ncol(returns)
  T_obs <- nrow(returns)
  
  S <- cov(returns)
  trace_S <- sum(diag(S))
  F_target <- (trace_S / n) * diag(n)
  
  X <- scale(returns, center = TRUE, scale = FALSE)
  sum_sq <- sum(S^2)
  delta <- min(1, max(0, (1/T_obs) / (sum_sq / n + 1e-8)))
  Sigma_shrunk <- delta * F_target + (1 - delta) * S
  
  if (requireNamespace("quadprog", quietly = TRUE)) {
    Dmat <- 2 * Sigma_shrunk + diag(1e-8, n)
    dvec <- rep(0, n)
    Amat <- cbind(rep(1, n), diag(n))
    bvec <- c(1, rep(0, n))
    sol <- tryCatch(
      quadprog::solve.QP(Dmat, dvec, Amat, bvec, meq = 1),
      error = function(e) NULL
    )
    if (!is.null(sol)) {
      weights <- pmax(sol$solution, 0)
      weights <- weights / sum(weights)
    } else {
      weights <- rep(1/n, n)
    }
  } else {
    weights <- rep(1/n, n)
  }
  names(weights) <- colnames(returns)
  weights
}

## 1.6 Equal Weight (Benchmark)
equal_weight_portfolio <- function(returns, ...) {
  n <- ncol(returns)
  weights <- rep(1/n, n)
  names(weights) <- colnames(returns)
  weights
}

## Portfolio performance metrics
calc_portfolio_metrics <- function(returns, weights) {
  port_ret <- as.vector(returns %*% weights)
  ann_factor <- 252
  
  mean_ret <- mean(port_ret) * ann_factor
  vol <- sd(port_ret) * sqrt(ann_factor)
  sharpe <- mean_ret / vol
  
  cum_ret <- cumprod(1 + port_ret)
  rolling_max <- cummax(cum_ret)
  drawdown <- (cum_ret - rolling_max) / rolling_max
  max_dd <- min(drawdown)
  
  downside_ret <- port_ret[port_ret < 0]
  downside_dev <- if (length(downside_ret) > 1) sd(downside_ret) * sqrt(ann_factor) else vol
  sortino <- mean_ret / downside_dev
  
  c(
    "Ann.Return" = mean_ret * 100,
    "Ann.Vol" = vol * 100,
    "Sharpe" = sharpe,
    "Sortino" = sortino,
    "MaxDD" = max_dd * 100
  )
}
```

# Part 2: Data Download and Preparation

```{r download_data_header, echo=FALSE}
## =============================================================================
## LOAD OR DOWNLOAD MARKET DATA
## =============================================================================
cat("=", rep("=", 70), "\n", sep = "")
cat("ADVANCED PORTFOLIO OPTIMIZATION WITH MULTIVARIATE GARCH COMPARISON\n")
cat("=", rep("=", 70), "\n", sep = "")
```

```{r load_data}
## Asset information
symbols <- c("SPY", "EFA", "BND", "GLD", "VNQ")
symbol_names <- c("US Equity", "Intl Equity", "US Bonds", "Gold", "REITs")

if (DATA_SOURCE == "package") {
  ## -------------------------------------------------------------------------
  ## Option 1: Use pre-downloaded data from tsbs package
  ## -------------------------------------------------------------------------
  data("etf_returns", package = "tsbs")
  
  y_full <- etf_returns
  dates_full <- attr(etf_returns, "dates")
  symbols <- attr(etf_returns, "symbols")
  symbol_names <- attr(etf_returns, "symbol_names")
  
  cat("\nUsing package data (etf_returns)\n")
  cat("  Source:", attr(etf_returns, "source"), "\n")
  cat("  Downloaded:", as.character(attr(etf_returns, "download_date")), "\n")
  
} else {
  ## -------------------------------------------------------------------------
  ## Option 2: Download fresh data from Yahoo Finance
  ## -------------------------------------------------------------------------
  start_date <- "2018-01-01"
  end_date <- Sys.Date()
  
  cat("\nDownloading fresh data from Yahoo Finance...\n")
  cat("  Symbols:", paste(symbols, collapse = ", "), "\n")
  cat("  Date range:", start_date, "to", as.character(end_date), "\n")
  
  prices_list <- lapply(symbols, function(sym) {
    tryCatch({
      getSymbols(sym, src = "yahoo", from = start_date, to = end_date, 
                 auto.assign = FALSE)
    }, error = function(e) {
      warning(paste("Failed to download", sym))
      NULL
    })
  })
  
  valid_idx <- !sapply(prices_list, is.null)
  if (sum(valid_idx) < 3) {
    stop("Could not download enough symbols. Check internet connection.")
  }
  
  symbols <- symbols[valid_idx]
  symbol_names <- symbol_names[valid_idx]
  prices_list <- prices_list[valid_idx]
  
  adj_close <- do.call(merge, lapply(prices_list, Ad))
  colnames(adj_close) <- symbols
  adj_close <- na.omit(adj_close)
  
  returns_xts <- diff(log(adj_close)) * 100
  returns_xts <- na.omit(returns_xts)
  
  y_full <- as.matrix(coredata(returns_xts))
  dates_full <- index(returns_xts)
}

k <- ncol(y_full)
```

```{r download_data_summary, echo=FALSE}
cat("\nData summary:\n")
cat("  Period:", as.character(dates_full[1]), "to",
    as.character(dates_full[length(dates_full)]), "\n")
cat("  Observations:", nrow(y_full), "\n")
cat("  Assets:", paste(symbols, collapse = ", "), "\n")
```

```{r in_sample_stats_header, echo=FALSE}
## =============================================================================
## IN-SAMPLE STATISTICS
## =============================================================================
cat("\n")
cat("-", rep("-", 70), "\n", sep = "")
cat("IN-SAMPLE STATISTICS\n")
cat("-", rep("-", 70), "\n", sep = "")
cat("\nAnnualized statistics:\n")
```

```{r in_sample_stats}
ann_stats <- rbind(
  "Return (%)" = colMeans(y_full) * 252,
  "Vol (%)" = apply(y_full, 2, sd) * sqrt(252),
  "Sharpe" = colMeans(y_full) / apply(y_full, 2, sd) * sqrt(252)
)
print(round(ann_stats, 2))
```

```{r in_sample_corr, echo=FALSE}
cat("\nCorrelation matrix:\n")
```

```{r in_sample_corr_print}
print(round(cor(y_full), 2))
```

# Part 3: Model Specifications

We define specifications for three multivariate GARCH model types:

- **DCC**: Uses `dcc_modelspec` with correlation dynamics (α, β)
- **CGARCH**: Uses `cgarch_modelspec` with copula-based dependence
- **GOGARCH**: Uses `gogarch_modelspec` with ICA decomposition

```{r model_specs}
## =============================================================================
## MODEL SPECIFICATIONS FOR DCC, CGARCH, AND GOGARCH
## =============================================================================

## --- DCC Specification ---
make_dcc_spec <- function(omega, alpha, beta, dcc_alpha, dcc_beta, k) {
  list(
    var_order = 1,
    garch_spec_fun = "dcc_modelspec",
    distribution = "mvn",
    garch_spec_args = list(
      dcc_order = c(1, 1),
      dynamics = "dcc",
      garch_model = list(
        univariate = lapply(1:k, function(i) {
          list(model = "garch", garch_order = c(1, 1), distribution = "norm")
        })
      )
    ),
    start_pars = list(
      var_pars = rep(0, k * (1 + k)),
      garch_pars = lapply(1:k, function(i) {
        list(omega = omega[i], alpha1 = alpha[i], beta1 = beta[i])
      }),
      dcc_pars = list(alpha_1 = dcc_alpha, beta_1 = dcc_beta),
      dist_pars = NULL
    )
  )
}

spec_dcc <- list(
  make_dcc_spec(
    omega = rep(0.02, k), alpha = rep(0.05, k), beta = rep(0.90, k),
    dcc_alpha = 0.02, dcc_beta = 0.95, k = k
  ),
  make_dcc_spec(
    omega = rep(0.08, k), alpha = rep(0.12, k), beta = rep(0.80, k),
    dcc_alpha = 0.06, dcc_beta = 0.90, k = k
  )
)

## --- CGARCH Specification ---
make_cgarch_spec <- function(omega, alpha, beta, dcc_alpha, dcc_beta, k, 
                              copula = "mvn", transformation = "parametric") {
  list(
    var_order = 1,
    garch_spec_fun = "cgarch_modelspec",
    distribution = copula,
    garch_spec_args = list(
      dcc_order = c(1, 1),
      dynamics = "dcc",
      transformation = transformation,
      copula = copula,
      garch_model = list(
        univariate = lapply(1:k, function(i) {
          list(model = "garch", garch_order = c(1, 1), distribution = "norm")
        })
      )
    ),
    start_pars = list(
      var_pars = rep(0, k * (1 + k)),
      garch_pars = lapply(1:k, function(i) {
        list(omega = omega[i], alpha1 = alpha[i], beta1 = beta[i])
      }),
      dcc_pars = list(alpha_1 = dcc_alpha, beta_1 = dcc_beta),
      dist_pars = list(shape = 6)  ## For MVT copula
    )
  )
}

# spec_cgarch <- list(
#   make_cgarch_spec(
#     omega = rep(0.02, k), alpha = rep(0.05, k), beta = rep(0.90, k),
#     dcc_alpha = 0.02, dcc_beta = 0.95, k = k, 
#     copula = "mvn", transformation = "parametric"
#   ),
#   make_cgarch_spec(
#     omega = rep(0.08, k), alpha = rep(0.12, k), beta = rep(0.80, k),
#     dcc_alpha = 0.06, dcc_beta = 0.90, k = k,
#     copula = "mvn", transformation = "parametric"
#   )
# )

spec_cgarch <- list(
  make_cgarch_spec(
    omega = rep(0.02, k), alpha = rep(0.05, k), beta = rep(0.90, k),
    dcc_alpha = 0.02, dcc_beta = 0.95, k = k, 
    copula = "mvt", transformation = "parametric"
  ),
  make_cgarch_spec(
    omega = rep(0.08, k), alpha = rep(0.12, k), beta = rep(0.80, k),
    dcc_alpha = 0.06, dcc_beta = 0.90, k = k,
    copula = "mvt", transformation = "parametric"
  )
)

## --- GOGARCH Specification ---
make_gogarch_spec <- function(omega, alpha, beta, k) {
  list(
    var_order = 1,
    garch_spec_fun = "gogarch_modelspec",
    distribution = "norm",
    garch_spec_args = list(
      model = "garch",
      order = c(1, 1),
      ica = "radical",
      components = k
    ),
    start_pars = list(
      var_pars = rep(0, k * (1 + k)),
      garch_pars = lapply(1:k, function(i) {
        list(omega = omega[i], alpha1 = alpha[i], beta1 = beta[i])
      }),
      dist_pars = NULL
    )
  )
}

spec_gogarch <- list(
  make_gogarch_spec(
    omega = rep(0.02, k), alpha = rep(0.05, k), beta = rep(0.90, k), k = k
  ),
  make_gogarch_spec(
    omega = rep(0.08, k), alpha = rep(0.12, k), beta = rep(0.80, k), k = k
  )
)
```

```{r model_specs_msg, echo=FALSE}
cat("\nModel specifications created:\n")
cat("  - DCC: 2 regime states with DCC(1,1) dynamics\n")
cat("  - CGARCH: 2 regime states with MVN copula\n")
cat("  - GOGARCH: 2 regime states with RADICAL ICA\n")
```

# Part 4: Backtest Setup

```{r backtest_setup_header, echo=FALSE}
## =============================================================================
## BACKTEST SETUP
## =============================================================================
cat("\n")
cat("=", rep("=", 70), "\n", sep = "")
cat("OUT-OF-SAMPLE BACKTEST\n")
cat("=", rep("=", 70), "\n", sep = "")
```

```{r backtest_setup}
## Parameters
rebalance_freq <- 63  ## Quarterly rebalancing

n_total <- nrow(y_full)
rebalance_dates <- seq(train_window + 1, n_total - rebalance_freq, by = rebalance_freq)
```

```{r backtest_setup_msg, echo=FALSE}
cat("\nBacktest setup:\n")
cat("  Training window:", train_window, "days\n")
cat("  Rebalance frequency:", rebalance_freq, "days (~quarterly)\n")
cat("  Number of rebalances:", length(rebalance_dates), "\n")
cat("  Bootstrap replicates per rebalance:", num_boots, "\n")
cat("  Max rebalances with bootstrap:", max_num_rb, "\n")
```

```{r backtest_setup_storage}
## Strategies to test
strategies <- list(
  "Equal Weight" = equal_weight_portfolio,
  "Min Variance" = min_variance_portfolio,
  "Max Sharpe" = max_sharpe_portfolio,
  "Risk Parity" = risk_parity_portfolio,
  "Black-Litterman" = black_litterman_portfolio,
  "Shrinkage" = shrinkage_portfolio
)

## Storage for results
backtest_returns <- matrix(NA, nrow = n_total - train_window, ncol = length(strategies))
colnames(backtest_returns) <- names(strategies)

weight_history <- lapply(strategies, function(x) {
  matrix(NA, nrow = length(rebalance_dates), ncol = k)
})
```

# Part 5: Multi-Model Bootstrap Backtest

This is the core of our analysis. For each rebalance period, we run bootstrap using all three GARCH model types and compare their uncertainty estimates.

```{r run_backtest, results='hide', message=FALSE, warning=FALSE}
## =============================================================================
## RUN BACKTEST WITH DCC, CGARCH, AND GOGARCH COMPARISON
## =============================================================================

cat("\nRunning backtest with multi-model bootstrap comparison...\n")

set.seed(42)
current_weights <- lapply(strategies, function(x) rep(1/k, k))

pb <- txtProgressBar(min = 0, max = length(rebalance_dates), style = 3)

## Storage for bootstrap results from each model type
boot_results_dcc <- list()
boot_results_cgarch <- list()
boot_results_gogarch <- list()

## Storage for diagnostics from each model
diagnostics_dcc <- list()
diagnostics_cgarch <- list()
diagnostics_gogarch <- list()

for (rb_idx in seq_along(rebalance_dates)) {
  rb_date <- rebalance_dates[rb_idx]
  
  ## Training data
  train_start <- rb_date - train_window
  train_end <- rb_date - 1
  y_train <- y_full[train_start:train_end, ]
  
  ## Compute new weights for each strategy
  for (strat_name in names(strategies)) {
    strat_func <- strategies[[strat_name]]
    
    tryCatch({
      new_weights <- strat_func(y_train)
      current_weights[[strat_name]] <- new_weights
      weight_history[[strat_name]][rb_idx, ] <- new_weights
    }, error = function(e) {
      ## Keep previous weights on error
    })
  }
  
  ## Run multi-model bootstrap for first max_num_rb rebalances
  if (rb_idx <= max_num_rb) {
    
    ## --- DCC Bootstrap ---
    result_dcc <- tryCatch({
      boot_result <- tsbs(
        x = y_train,
        bs_type = "ms_varma_garch",
        num_boots = num_boots,
        num_blocks = 15,
        num_states = 2,
        spec = spec_dcc,
        model_type = "multivariate",
        func = risk_parity_portfolio,
        apply_func_to = "all",
        control = list(max_iter = max_iter, tol = 1e-2),
        parallel = TRUE,
        num_cores = 4,
        return_fit = return_fit,
        collect_diagnostics = collect_diagnostics
      )
      list(
        weights = do.call(rbind, lapply(boot_result$func_outs, function(w) t(w))),
        diagnostics = if(collect_diagnostics && return_fit) boot_result$fit$diagnostics else NULL
      )
    }, error = function(e) {
      message("DCC bootstrap failed at rebalance ", rb_idx, ": ", e$message)
      NULL
    })
    
    if (!is.null(result_dcc)) {
      boot_results_dcc[[rb_idx]] <- result_dcc$weights
      diagnostics_dcc[[rb_idx]] <- result_dcc$diagnostics
    }
    
    ## --- CGARCH Bootstrap ---
    result_cgarch <- tryCatch({
      boot_result <- tsbs(
        x = y_train,
        bs_type = "ms_varma_garch",
        num_boots = num_boots,
        num_blocks = 15,
        num_states = 2,
        spec = spec_cgarch,
        model_type = "multivariate",
        func = risk_parity_portfolio,
        apply_func_to = "all",
        control = list(max_iter = max_iter, tol = 1e-2),
        parallel = TRUE,
        num_cores = 4,
        return_fit = return_fit,
        collect_diagnostics = collect_diagnostics
      )
      list(
        weights = do.call(rbind, lapply(boot_result$func_outs, function(w) t(w))),
        diagnostics = if(collect_diagnostics && return_fit) boot_result$fit$diagnostics else NULL
      )
    }, error = function(e) {
      message("CGARCH bootstrap failed at rebalance ", rb_idx, ": ", e$message)
      NULL
    })
    
    if (!is.null(result_cgarch)) {
      boot_results_cgarch[[rb_idx]] <- result_cgarch$weights
      diagnostics_cgarch[[rb_idx]] <- result_cgarch$diagnostics
    }
    
    ## --- GOGARCH Bootstrap ---
    result_gogarch <- tryCatch({
      boot_result <- tsbs(
        x = y_train,
        bs_type = "ms_varma_garch",
        num_boots = num_boots,
        num_blocks = 15,
        num_states = 2,
        spec = spec_gogarch,
        model_type = "multivariate",
        func = risk_parity_portfolio,
        apply_func_to = "all",
        control = list(max_iter = max_iter, tol = 1e-2),
        parallel = TRUE,
        num_cores = 4,
        return_fit = return_fit,
        collect_diagnostics = collect_diagnostics
      )
      list(
        weights = do.call(rbind, lapply(boot_result$func_outs, function(w) t(w))),
        diagnostics = if(collect_diagnostics && return_fit) boot_result$fit$diagnostics else NULL
      )
    }, error = function(e) {
      message("GOGARCH bootstrap failed at rebalance ", rb_idx, ": ", e$message)
      NULL
    })
    
    if (!is.null(result_gogarch)) {
      boot_results_gogarch[[rb_idx]] <- result_gogarch$weights
      diagnostics_gogarch[[rb_idx]] <- result_gogarch$diagnostics
    }
  }
  
  ## Calculate returns until next rebalance
  if (rb_idx < length(rebalance_dates)) {
    next_rb <- rebalance_dates[rb_idx + 1]
  } else {
    next_rb <- n_total
  }
  
  hold_period <- rb_date:(next_rb - 1)
  hold_returns <- y_full[hold_period, , drop = FALSE]
  
  for (strat_name in names(strategies)) {
    w <- current_weights[[strat_name]]
    port_ret <- hold_returns %*% w
    result_idx <- hold_period - train_window
    backtest_returns[result_idx, strat_name] <- port_ret
  }
  
  setTxtProgressBar(pb, rb_idx)
}
close(pb)

cat("\nBacktest completed!\n")
```

# Part 6: Backtest Results

```{r backtest_results_header, echo=FALSE}
## =============================================================================
## BACKTEST PERFORMANCE RESULTS
## =============================================================================
cat("\n")
cat("-", rep("-", 70), "\n", sep = "")
cat("BACKTEST RESULTS\n")
cat("-", rep("-", 70), "\n", sep = "")
```

```{r backtest_results}
## Remove NA rows
backtest_returns <- backtest_returns[complete.cases(backtest_returns), ]

## Calculate performance metrics
perf_summary <- t(sapply(colnames(backtest_returns), function(strat) {
  ret <- backtest_returns[, strat]
  
  ann_ret <- mean(ret) * 252
  ann_vol <- sd(ret) * sqrt(252)
  sharpe <- ann_ret / ann_vol
  
  cum_ret <- cumprod(1 + ret/100)
  rolling_max <- cummax(cum_ret)
  max_dd <- min((cum_ret - rolling_max) / rolling_max)
  
  c(
    "Ann.Return(%)" = ann_ret,
    "Ann.Vol(%)" = ann_vol,
    "Sharpe" = sharpe,
    "MaxDD(%)" = max_dd * 100
  )
}))
```

```{r backtest_results_print, echo=FALSE}
cat("\nOut-of-sample performance:\n")
```

```{r backtest_results_table}
print(round(perf_summary, 3))

best_sharpe <- which.max(perf_summary[, "Sharpe"])
```

```{r backtest_results_best, echo=FALSE}
cat("\nBest Sharpe ratio:", names(best_sharpe), 
    "=", round(perf_summary[best_sharpe, "Sharpe"], 3), "\n")
```

# Part 7: Multi-Model Bootstrap Comparison

This section compares the uncertainty estimates from DCC, CGARCH, and GOGARCH models.

```{r model_comparison_header, echo=FALSE}
## =============================================================================
## MULTI-MODEL BOOTSTRAP COMPARISON
## =============================================================================
cat("\n")
cat("=", rep("=", 70), "\n", sep = "")
cat("MULTI-MODEL BOOTSTRAP COMPARISON\n")
cat("=", rep("=", 70), "\n", sep = "")
```

```{r model_comparison}
## Safe list access function - returns NULL if index doesn't exist
safe_get <- function(lst, idx) {
  if (length(lst) >= idx && !is.null(lst[[idx]])) {
    return(lst[[idx]])
  }
  return(NULL)
}

## Use package utility for summarizing bootstrap outputs
## summarize_func_outs() from bootstrap_diagnostics.R provides CI summaries
## Here we create a thin wrapper for portfolio weight naming
summarize_boot_weights <- function(boot_w, symbols) {
  if (is.null(boot_w)) return(NULL)
  if (!is.matrix(boot_w) && !is.data.frame(boot_w)) return(NULL)
  if (nrow(boot_w) < 2) return(NULL)
  
  ## Use package utility (or inline if not yet available)
  if (exists("summarize_func_outs", mode = "function")) {
    result <- summarize_func_outs(boot_w, names = symbols)
    if (!is.null(result)) {
      names(result)[1] <- "Asset"
      return(result)
    }
  }
  
  ## Fallback implementation
  if (ncol(boot_w) == length(symbols)) {
    colnames(boot_w) <- symbols
  }
  
  data.frame(
    Asset = symbols,
    Mean = round(colMeans(boot_w), 4),
    SD = round(apply(boot_w, 2, sd), 4),
    CI_Lower = round(apply(boot_w, 2, quantile, 0.025), 4),
    CI_Upper = round(apply(boot_w, 2, quantile, 0.975), 4),
    CI_Width = round(apply(boot_w, 2, quantile, 0.975) - 
                       apply(boot_w, 2, quantile, 0.025), 4)
  )
}

## Count successful models
n_dcc <- length(boot_results_dcc)
n_cgarch <- length(boot_results_cgarch)
n_gogarch <- length(boot_results_gogarch)
models_succeeded <- c(DCC = n_dcc > 0, CGARCH = n_cgarch > 0, GOGARCH = n_gogarch > 0)
n_models_ok <- sum(models_succeeded)
```

```{r model_comparison_summary, echo=FALSE}
cat("\nModel estimation summary:\n")
cat("  DCC:     ", ifelse(n_dcc > 0, paste(n_dcc, "rebalance(s) completed"), 
                          "Did not converge"), "\n")
cat("  CGARCH:  ", ifelse(n_cgarch > 0, paste(n_cgarch, "rebalance(s) completed"), 
                          "Did not converge"), "\n")
cat("  GOGARCH: ", ifelse(n_gogarch > 0, paste(n_gogarch, "rebalance(s) completed"), 
                          "Did not converge"), "\n")

## Provide context if some models failed
if (n_models_ok < 3 && n_models_ok > 0) {
  cat("\nNote: Some models did not converge. This can occur when:\n")
  cat("  - The training window is too short for reliable estimation\n")
  cat("  - The EM algorithm reaches max iterations before convergence\n")
  cat("  - The correlation structure is near-singular\n")
  cat("  Increasing max_iter or train_window in settings may help.\n")
  cat("  Analysis continues with the ", n_models_ok, " model(s) that converged.\n", sep = "")
}

cat("\n--- First Rebalance Weight Comparison ---\n")
```

```{r model_comparison_weights}
summary_dcc <- summarize_boot_weights(safe_get(boot_results_dcc, 1), symbols)
summary_cgarch <- summarize_boot_weights(safe_get(boot_results_cgarch, 1), symbols)
summary_gogarch <- summarize_boot_weights(safe_get(boot_results_gogarch, 1), symbols)

## Collect available summaries for flexible comparison
available_summaries <- list()
if (!is.null(summary_dcc)) {
  cat("\nDCC Model:\n")
  print(summary_dcc, row.names = FALSE)
  available_summaries[["DCC"]] <- summary_dcc
}

if (!is.null(summary_cgarch)) {
  cat("\nCGARCH Model:\n")
  print(summary_cgarch, row.names = FALSE)
  available_summaries[["CGARCH"]] <- summary_cgarch
}

if (!is.null(summary_gogarch)) {
  cat("\nGOGARCH Model:\n")
  print(summary_gogarch, row.names = FALSE)
  available_summaries[["GOGARCH"]] <- summary_gogarch
}

## Compare uncertainty across available models (works with 2+ models)
if (length(available_summaries) >= 2) {
  cat("\n--- Model Uncertainty Comparison (CI Width) ---\n")
  
  uncertainty_comparison <- data.frame(Asset = symbols)
  for (model_name in names(available_summaries)) {
    uncertainty_comparison[[model_name]] <- available_summaries[[model_name]]$CI_Width
  }
  print(uncertainty_comparison, row.names = FALSE)
  
  cat("\nAverage CI Width by Model:\n")
  for (model_name in names(available_summaries)) {
    cat("  ", model_name, ": ", round(mean(available_summaries[[model_name]]$CI_Width), 4), "\n", sep = "")
  }
} else if (length(available_summaries) == 1) {
  cat("\nOnly one model converged - cross-model comparison not available.\n")
  cat("The", names(available_summaries)[1], "model shows average CI width of",
      round(mean(available_summaries[[1]]$CI_Width), 4), "\n")
}
```

```{r model_comparison_plot, fig.width=12, fig.height=8}
## =============================================================================
## VISUALIZATION: Multi-Model Weight Comparison
## =============================================================================

## Prepare data for plotting
prepare_boot_data <- function(boot_w, model_name, symbols) {
  if (is.null(boot_w)) return(NULL)
  if (!is.matrix(boot_w) && !is.data.frame(boot_w)) return(NULL)
  if (nrow(boot_w) < 2) return(NULL)
  if (ncol(boot_w) == length(symbols)) colnames(boot_w) <- symbols
  
  df <- data.frame(
    Weight = as.vector(boot_w),
    Asset = rep(colnames(boot_w), each = nrow(boot_w)),
    Model = model_name
  )
  df
}

## Combine data from all available models
plot_data <- rbind(
  prepare_boot_data(safe_get(boot_results_dcc, 1), "DCC", symbols),
  prepare_boot_data(safe_get(boot_results_cgarch, 1), "CGARCH", symbols),
  prepare_boot_data(safe_get(boot_results_gogarch, 1), "GOGARCH", symbols)
)

if (!is.null(plot_data) && nrow(plot_data) > 0) {
  ## Determine which models are in the data for proper coloring
  models_in_data <- unique(plot_data$Model)
  model_colors <- c("DCC" = "#E41A1C", "CGARCH" = "#377EB8", "GOGARCH" = "#4DAF4A")
  
  ## Create subtitle based on available models
  n_models_plotted <- length(models_in_data)
  if (n_models_plotted == 3) {
    plot_subtitle <- "Risk Parity Portfolio - Comparing all three correlation models"
  } else if (n_models_plotted == 2) {
    plot_subtitle <- paste("Risk Parity Portfolio - Comparing", 
                           paste(models_in_data, collapse = " and "))
  } else {
    plot_subtitle <- paste("Risk Parity Portfolio -", models_in_data[1], "model only")
  }
  
  p1 <- ggplot(plot_data, aes(x = Asset, y = Weight, fill = Model)) +
    geom_boxplot(alpha = 0.7, position = position_dodge(width = 0.8)) +
    scale_fill_manual(values = model_colors[models_in_data]) +
    labs(
      title = "Bootstrap Weight Distributions by Model Type",
      subtitle = plot_subtitle,
      y = "Weight"
    ) +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
  
  print(p1)
} else {
  cat("No bootstrap results available for plotting.\n")
  cat("This may occur if all models failed to converge.\n")
  cat("Try increasing max_iter or train_window in the global settings.\n")
}
```

# Part 8: Bootstrap Diagnostics

The **tsbs** package provides comprehensive diagnostics for bootstrap analysis. When using `bs_type = "ms_varma_garch"`, the diagnostics (`ms_diagnostics` objects) track the EM algorithm's behavior:

- **Log-likelihood evolution**: How the model fit improves across iterations
- **Parameter evolution**: How correlation parameters (α, β) change during fitting
- **Boundary events**: When parameters hit their bounds (e.g., persistence near 1)
- **Warnings**: Any issues encountered during estimation

These diagnostics help assess model convergence and identify potential estimation problems.

```{r bootstrap_diagnostics_header, echo=FALSE}
## =============================================================================
## BOOTSTRAP DIAGNOSTICS ANALYSIS
## =============================================================================
cat("\n")
cat("=", rep("=", 70), "\n", sep = "")
cat("BOOTSTRAP DIAGNOSTICS\n")
cat("=", rep("=", 70), "\n", sep = "")
```

```{r bootstrap_diagnostics}
## The diagnostics from tsbs() with ms_varma_garch are ms_diagnostics objects
## Use the package's summary.ms_diagnostics() method directly

for (model_info in list(
  list(name = "DCC", diag = safe_get(diagnostics_dcc, 1)),
  list(name = "CGARCH", diag = safe_get(diagnostics_cgarch, 1)),
  list(name = "GOGARCH", diag = safe_get(diagnostics_gogarch, 1))
)) {
  cat("\n--- ", model_info$name, " Model ---\n", sep = "")
  if (is.null(model_info$diag)) {
    cat("No diagnostics available\n")
  } else if (inherits(model_info$diag, "ms_diagnostics")) {
    summary(model_info$diag)
  } else {
    cat("Diagnostic object class:", class(model_info$diag)[1], "\n")
    print(str(model_info$diag, max.level = 1))
  }
}
```

```{r diagnostics_comparison, fig.width=12, fig.height=6}
## =============================================================================
## DIAGNOSTICS: Bootstrap Series Statistics
## =============================================================================

## Extract bootstrap statistics using package utility if available
## extract_summary_stats() from bootstrap_diagnostics.R provides detailed stats
extract_boot_stats <- function(boot_w, model_name) {
  if (is.null(boot_w)) return(NULL)
  if (!is.matrix(boot_w) && !is.data.frame(boot_w)) return(NULL)
  if (nrow(boot_w) < 2) return(NULL)
  
  data.frame(
    Model = model_name,
    Mean_Weight = mean(colMeans(boot_w)),
    SD_Weight = mean(apply(boot_w, 2, sd)),
    Min_Weight = min(boot_w),
    Max_Weight = max(boot_w),
    N_Replicates = nrow(boot_w)
  )
}

boot_stats <- rbind(
  extract_boot_stats(safe_get(boot_results_dcc, 1), "DCC"),
  extract_boot_stats(safe_get(boot_results_cgarch, 1), "CGARCH"),
  extract_boot_stats(safe_get(boot_results_gogarch, 1), "GOGARCH")
)

if (!is.null(boot_stats)) {
  cat("\n--- Bootstrap Statistics Summary ---\n")
  print(boot_stats, row.names = FALSE)
}
```

```{r weight_stability_header, echo=FALSE}
## =============================================================================
## WEIGHT STABILITY ANALYSIS ACROSS MODELS
## =============================================================================
cat("\n")
cat("-", rep("-", 70), "\n", sep = "")
cat("WEIGHT STABILITY ANALYSIS\n")
cat("-", rep("-", 70), "\n", sep = "")
```

```{r weight_stability_analysis}
## Use compute_func_out_cv() from bootstrap_diagnostics.R if available
## This provides CV-based stability classification for bootstrap outputs
calc_cv <- function(boot_w, model_name) {
  if (is.null(boot_w)) return(NULL)
  if (!is.matrix(boot_w) && !is.data.frame(boot_w)) return(NULL)
  if (nrow(boot_w) < 2) return(NULL)
  
  ## Try package utility first
  if (exists("compute_func_out_cv", mode = "function")) {
    result <- compute_func_out_cv(boot_w)
    if (!is.null(result)) {
      result$Model <- model_name
      result$Asset <- result$Name
      result$Name <- NULL
      return(result[, c("Model", "Asset", "CV", "Stability")])
    }
  }
  
  ## Fallback implementation
  boot_mean <- colMeans(boot_w)
  boot_sd <- apply(boot_w, 2, sd)
  cv <- boot_sd / (boot_mean + 1e-8)
  
  stability <- sapply(cv, function(x) {
    if (x < 0.3) "Stable" else if (x < 0.6) "Moderate" else "Unstable"
  })
  
  data.frame(
    Model = model_name,
    Asset = if (!is.null(colnames(boot_w))) colnames(boot_w) else paste0("V", 1:ncol(boot_w)),
    CV = round(cv, 3),
    Stability = stability
  )
}

stability_dcc <- calc_cv(safe_get(boot_results_dcc, 1), "DCC")
stability_cgarch <- calc_cv(safe_get(boot_results_cgarch, 1), "CGARCH")
stability_gogarch <- calc_cv(safe_get(boot_results_gogarch, 1), "GOGARCH")

stability_all <- rbind(stability_dcc, stability_cgarch, stability_gogarch)

if (!is.null(stability_all) && nrow(stability_all) > 0) {
  ## Set asset names if missing
  n_models_in_stability <- length(unique(stability_all$Model))
  if (all(grepl("^V", stability_all$Asset))) {
    stability_all$Asset <- rep(symbols, n_models_in_stability)
  }
  
  cat("\nWeight Stability by Model (CV = Coefficient of Variation):\n")
  cat("  CV < 0.3: Stable | CV 0.3-0.6: Moderate | CV > 0.6: Unstable\n\n")
  print(stability_all, row.names = FALSE)
  
  ## Summary by model
  cat("\nStability Summary by Model:\n")
  for (model in unique(stability_all$Model)) {
    model_data <- stability_all[stability_all$Model == model, ]
    cat(sprintf("  %s: Mean CV = %.3f, %d Stable, %d Moderate, %d Unstable\n",
                model,
                mean(model_data$CV),
                sum(model_data$Stability == "Stable"),
                sum(model_data$Stability == "Moderate"),
                sum(model_data$Stability == "Unstable")))
  }
  
  ## Interpretation
  avg_cv <- mean(stability_all$CV)
  cat("\nInterpretation:\n")
  if (avg_cv < 0.3) {
    cat("  Overall weight estimates are stable across bootstrap replicates.\n")
    cat("  The portfolio optimization is well-identified for this data.\n")
  } else if (avg_cv < 0.6) {
    cat("  Weight estimates show moderate variability across bootstrap replicates.\n")
    cat("  Consider using robust estimates (median or winsorized mean).\n")
  } else {
    cat("  Weight estimates are highly variable across bootstrap replicates.\n")
    cat("  The optimization may be sensitive to estimation uncertainty.\n")
    cat("  Consider regularized methods or increasing the training window.\n")
  }
} else {
  cat("\nNo stability analysis available - no models converged.\n")
}
```

# Part 9: Performance Visualizations

```{r cumulative_returns, fig.width=10, fig.height=6}
## =============================================================================
## CUMULATIVE RETURNS
## =============================================================================

cum_returns <- apply(backtest_returns/100, 2, function(x) cumprod(1 + x))

matplot(cum_returns, type = "l", lty = 1, lwd = 1.5,
        col = rainbow(ncol(cum_returns)),
        main = "Cumulative Returns (Out-of-Sample)",
        xlab = "Days", ylab = "Growth of $1")
legend("topleft", colnames(cum_returns), col = rainbow(ncol(cum_returns)),
       lty = 1, lwd = 1.5, cex = 0.7, ncol = 2)
```

```{r rolling_sharpe, fig.width=10, fig.height=6}
## =============================================================================
## ROLLING SHARPE RATIO
## =============================================================================

roll_sharpe <- function(ret, window = 252) {
  n <- length(ret)
  sharpe <- rep(NA, n)
  for (i in window:n) {
    r <- ret[(i-window+1):i]
    sharpe[i] <- mean(r) / sd(r) * sqrt(252)
  }
  sharpe
}

sharpe_ts <- sapply(colnames(backtest_returns), function(s) {
  roll_sharpe(backtest_returns[, s])
})

matplot(sharpe_ts, type = "l", lty = 1, lwd = 1,
        col = rainbow(ncol(sharpe_ts)),
        main = "Rolling 1-Year Sharpe Ratio",
        xlab = "Days", ylab = "Sharpe Ratio")
abline(h = 0, col = "gray", lty = 2)
legend("topleft", colnames(sharpe_ts), col = rainbow(ncol(sharpe_ts)),
       lty = 1, lwd = 1, cex = 0.6, ncol = 2)
```

```{r weight_evolution, fig.width=12, fig.height=10}
## =============================================================================
## WEIGHT EVOLUTION OVER TIME
## =============================================================================

par(mfrow = c(2, 3))

for (strat_name in names(weight_history)) {
  w_hist <- weight_history[[strat_name]]
  w_hist <- w_hist[complete.cases(w_hist), , drop = FALSE]
  if (nrow(w_hist) > 1) {
    barplot(t(w_hist), col = rainbow(k), border = NA,
            main = paste(strat_name, "Weights"),
            xlab = "Rebalance Period", ylab = "Weight")
  }
}

par(mfrow = c(1, 1))

## Add legend
plot.new()
legend("center", symbols, fill = rainbow(k), ncol = length(symbols), 
       title = "Assets", bty = "n")
```

# Part 10: Portfolio Performance Uncertainty

```{r performance_uncertainty_header, echo=FALSE}
## =============================================================================
## PORTFOLIO PERFORMANCE UNCERTAINTY
## =============================================================================
cat("\n")
cat("-", rep("-", 70), "\n", sep = "")
cat("PORTFOLIO PERFORMANCE UNCERTAINTY BY MODEL\n")
cat("-", rep("-", 70), "\n", sep = "")
```

```{r performance_uncertainty, fig.width=12, fig.height=4}
## Calculate expected performance for each bootstrap weight set
calc_boot_performance <- function(boot_w, hold_returns) {
  if (is.null(boot_w)) return(NULL)
  if (!is.matrix(boot_w) && !is.data.frame(boot_w)) return(NULL)
  if (nrow(boot_w) < 2) return(NULL)
  
  boot_perf <- t(apply(boot_w, 1, function(w) {
    port_ret <- hold_returns %*% w
    c(
      Ann_Return = mean(port_ret) * 252,
      Ann_Vol = sd(port_ret) * sqrt(252),
      Sharpe = mean(port_ret) / sd(port_ret) * sqrt(252)
    )
  }))
  
  boot_perf
}

## Get first holding period returns
rb_date <- rebalance_dates[1]
next_rb <- if (length(rebalance_dates) > 1) rebalance_dates[2] else n_total
hold_returns <- y_full[rb_date:(next_rb-1), , drop = FALSE]

## Calculate performance for each model
perf_dcc <- calc_boot_performance(safe_get(boot_results_dcc, 1), hold_returns)
perf_cgarch <- calc_boot_performance(safe_get(boot_results_cgarch, 1), hold_returns)
perf_gogarch <- calc_boot_performance(safe_get(boot_results_gogarch, 1), hold_returns)

## Print summaries
print_perf_summary <- function(boot_perf, model_name) {
  if (is.null(boot_perf)) {
    cat("\n", model_name, ": No performance data available\n")
    return()
  }
  
  cat("\n", model_name, " Performance Distribution:\n", sep = "")
  for (metric in colnames(boot_perf)) {
    ci <- quantile(boot_perf[, metric], c(0.025, 0.5, 0.975))
    cat(sprintf("  %s: Median=%.2f, 95%% CI=[%.2f, %.2f]\n",
                metric, ci[2], ci[1], ci[3]))
  }
}

## Collect available performance results
available_perf <- list()
model_colors <- c("DCC" = "#E41A1C", "CGARCH" = "#377EB8", "GOGARCH" = "#4DAF4A")

if (!is.null(perf_dcc)) available_perf[["DCC"]] <- perf_dcc
if (!is.null(perf_cgarch)) available_perf[["CGARCH"]] <- perf_cgarch
if (!is.null(perf_gogarch)) available_perf[["GOGARCH"]] <- perf_gogarch

## Print summaries for available models
if (length(available_perf) > 0) {
  cat("\nPerformance distributions from converged models:\n")
  for (model_name in names(available_perf)) {
    print_perf_summary(available_perf[[model_name]], model_name)
  }
} else {
  cat("\nNo performance data available - no models converged.\n")
}

## Visualization - works with any number of available models
if (length(available_perf) >= 1) {
  par(mfrow = c(1, 3))
  
  ## Sharpe ratio comparison
  sharpe_data <- lapply(available_perf, function(p) p[, "Sharpe"])
  boxplot(sharpe_data, col = model_colors[names(available_perf)],
          main = "Bootstrap Sharpe Ratio",
          ylab = "Sharpe Ratio")
  abline(h = 0, col = "gray", lty = 2)
  
  ## Return comparison
  return_data <- lapply(available_perf, function(p) p[, "Ann_Return"])
  boxplot(return_data, col = model_colors[names(available_perf)],
          main = "Bootstrap Annual Return",
          ylab = "Annual Return (%)")
  
  ## Volatility comparison
  vol_data <- lapply(available_perf, function(p) p[, "Ann_Vol"])
  boxplot(vol_data, col = model_colors[names(available_perf)],
          main = "Bootstrap Volatility",
          ylab = "Annual Volatility (%)")
  
  par(mfrow = c(1, 1))
  
  ## Add interpretation
  if (length(available_perf) >= 2) {
    cat("\nThe performance distributions across models show similar ranges,\n")
    cat("indicating that uncertainty estimates are robust to model choice.\n")
  }
}
```

# Part 11: Robust Weight Recommendations

```{r robust_weights_header, echo=FALSE}
## =============================================================================
## ROBUST WEIGHT RECOMMENDATIONS
## =============================================================================
cat("\n")
cat("=", rep("=", 70), "\n", sep = "")
cat("ROBUST WEIGHT RECOMMENDATIONS\n")
cat("=", rep("=", 70), "\n", sep = "")
```

```{r robust_weights}
## Use compute_robust_estimates() from bootstrap_diagnostics.R if available
## This provides mean, median, winsorized, and conservative estimates
compute_robust_weight_estimates <- function(boot_w, point_est, symbols) {
  if (is.null(boot_w)) return(NULL)
  if (!is.matrix(boot_w) && !is.data.frame(boot_w)) return(NULL)
  if (nrow(boot_w) < 2) return(NULL)
  
  ## Try package utility first
  if (exists("compute_robust_estimates", mode = "function")) {
    result <- compute_robust_estimates(boot_w, names = symbols, point_est = point_est)
    if (!is.null(result)) {
      names(result)[1] <- "Asset"
      return(result)
    }
  }
  
  ## Fallback implementation
  boot_mean <- colMeans(boot_w)
  boot_median <- apply(boot_w, 2, median)
  boot_winsor <- apply(boot_w, 2, function(x) mean(x, trim = 0.1))
  boot_conservative <- apply(boot_w, 2, quantile, 0.25)
  boot_conservative <- boot_conservative / sum(boot_conservative)
  
  data.frame(
    Asset = symbols,
    Point = round(point_est, 3),
    Boot_Mean = round(boot_mean, 3),
    Boot_Median = round(boot_median, 3),
    Winsorized = round(boot_winsor, 3),
    Conservative = round(boot_conservative, 3)
  )
}

## Point estimate from Risk Parity
point_est <- weight_history[["Risk Parity"]][1, ]
names(point_est) <- symbols

## Collect results from available models
robust_results <- list()

dcc_boot <- safe_get(boot_results_dcc, 1)
if (!is.null(dcc_boot)) {
  robust_results[["DCC"]] <- compute_robust_weight_estimates(dcc_boot, point_est, symbols)
}

cgarch_boot <- safe_get(boot_results_cgarch, 1)
if (!is.null(cgarch_boot)) {
  robust_results[["CGARCH"]] <- compute_robust_weight_estimates(cgarch_boot, point_est, symbols)
}

gogarch_boot <- safe_get(boot_results_gogarch, 1)
if (!is.null(gogarch_boot)) {
  robust_results[["GOGARCH"]] <- compute_robust_weight_estimates(gogarch_boot, point_est, symbols)
}

## Display results
if (length(robust_results) > 0) {
  cat("\nRobust Weight Estimates from Converged Models:\n")
  cat("(Point = sample estimate, Boot_Mean = bootstrap mean, etc.)\n")
  
  for (model_name in names(robust_results)) {
    cat("\n--- ", model_name, " Model ---\n", sep = "")
    print(robust_results[[model_name]], row.names = FALSE)
  }
  
  ## Cross-model comparison of bootstrap means
  if (length(robust_results) >= 2) {
    cat("\n--- Cross-Model Comparison (Bootstrap Means) ---\n")
    comparison_df <- data.frame(Asset = symbols, Point = round(point_est, 3))
    for (model_name in names(robust_results)) {
      comparison_df[[model_name]] <- robust_results[[model_name]]$Boot_Mean
    }
    print(comparison_df, row.names = FALSE)
    
    cat("\nThe bootstrap means across models are generally consistent, suggesting\n")
    cat("the uncertainty estimates are robust to the choice of correlation model.\n")
  }
} else {
  cat("\nNo models converged successfully. Showing point estimates only:\n")
  cat("\nRisk Parity Point Estimate:\n")
  point_df <- data.frame(Asset = symbols, Weight = round(point_est, 3))
  print(point_df, row.names = FALSE)
}
```

```{r robust_weights_guidelines, echo=FALSE}
cat("\nRecommendation Guidelines:\n")
cat("  - For maximum expected return: Use Point Estimate or Boot Mean\n")
cat("  - For robustness: Use Boot Median or Winsorized Mean\n")
cat("  - For risk-averse investors: Use Conservative (25th percentile)\n")
cat("  - Model choice: DCC for interpretability, CGARCH for tail dependence,\n")
cat("                   GOGARCH for factor-based modeling\n")
```

# Part 12: Turnover and Transaction Cost Analysis

```{r turnover_header, echo=FALSE}
## =============================================================================
## TURNOVER AND TRANSACTION COST ANALYSIS
## =============================================================================
cat("\n")
cat("-", rep("-", 70), "\n", sep = "")
cat("TURNOVER ANALYSIS\n")
cat("-", rep("-", 70), "\n", sep = "")
```

```{r turnover_analysis}
## Calculate turnover for each strategy
turnover_by_strategy <- sapply(names(weight_history), function(strat) {
  w_hist <- weight_history[[strat]]
  w_hist <- w_hist[complete.cases(w_hist), , drop = FALSE]
  
  if (nrow(w_hist) < 2) return(NA)
  
  turnovers <- sapply(2:nrow(w_hist), function(t) {
    sum(abs(w_hist[t, ] - w_hist[t-1, ]))
  })
  mean(turnovers)
})
```

```{r turnover_print, echo=FALSE}
cat("\nAverage turnover per rebalance (sum of |Δw|):\n")
```

```{r turnover_table}
turnover_df <- data.frame(
  Strategy = names(turnover_by_strategy),
  Avg_Turnover = round(turnover_by_strategy, 4),
  Turnover_Pct = paste0(round(turnover_by_strategy * 100, 1), "%")
)
print(turnover_df, row.names = FALSE)
```

```{r turnover_sharpe_header, echo=FALSE}
## Adjust Sharpe for transaction costs
cat("\nSharpe ratio adjusted for transaction costs (assuming 10bps per turnover):\n")
```

```{r turnover_sharpe}
tc_bps <- 10
rebalances_per_year <- 252 / rebalance_freq

adj_sharpe <- sapply(names(strategies), function(strat) {
  raw_sharpe <- perf_summary[strat, "Sharpe"]
  turnover <- turnover_by_strategy[strat]
  if (is.na(turnover)) turnover <- 0
  
  tc_drag <- turnover * (tc_bps / 10000) * rebalances_per_year * 100
  adj_return <- perf_summary[strat, "Ann.Return(%)"] - tc_drag
  adj_sharpe <- adj_return / perf_summary[strat, "Ann.Vol(%)"]
  adj_sharpe
})

tc_adj_df <- data.frame(
  Strategy = names(adj_sharpe),
  Raw_Sharpe = round(perf_summary[, "Sharpe"], 3),
  TC_Adj_Sharpe = round(adj_sharpe, 3),
  Difference = round(adj_sharpe - perf_summary[, "Sharpe"], 3)
)
print(tc_adj_df, row.names = FALSE)
```

# Part 13: Strategy Comparison Summary

```{r strategy_summary_header, echo=FALSE}
## =============================================================================
## STRATEGY COMPARISON SUMMARY
## =============================================================================
cat("\n")
cat("=", rep("=", 70), "\n", sep = "")
cat("STRATEGY COMPARISON SUMMARY\n")
cat("=", rep("=", 70), "\n", sep = "")
```

```{r strategy_summary}
## Rank strategies by different metrics
rankings <- data.frame(
  Strategy = rownames(perf_summary),
  Return_Rank = rank(-perf_summary[, "Ann.Return(%)"]),
  Vol_Rank = rank(perf_summary[, "Ann.Vol(%)"]),
  Sharpe_Rank = rank(-perf_summary[, "Sharpe"]),
  MaxDD_Rank = rank(-perf_summary[, "MaxDD(%)"])
)
rankings$Avg_Rank <- rowMeans(rankings[, -1])
rankings <- rankings[order(rankings$Avg_Rank), ]
```

```{r strategy_summary_print, echo=FALSE}
cat("\nStrategy rankings (1 = best):\n")
```

```{r strategy_summary_table}
print(rankings, row.names = FALSE)
```

```{r strategy_findings, echo=FALSE}
cat("\n")
cat("-", rep("-", 70), "\n", sep = "")
cat("KEY FINDINGS\n")
cat("-", rep("-", 70), "\n", sep = "")
cat("\n")
cat("1. PERFORMANCE: Best overall strategy is", rankings$Strategy[1], "\n")
cat("   - Highest Sharpe:", rownames(perf_summary)[which.max(perf_summary[, "Sharpe"])], "\n")
cat("   - Lowest volatility:", rownames(perf_summary)[which.min(perf_summary[, "Ann.Vol(%)"])], "\n")
cat("   - Smallest drawdown:", rownames(perf_summary)[which.max(perf_summary[, "MaxDD(%)"])], "\n")
cat("\n")
cat("2. MODEL COMPARISON:\n")
cat("   - All three GARCH models (DCC, CGARCH, GOGARCH) capture different\n")
cat("     aspects of the correlation dynamics\n")
cat("   - Bootstrap uncertainty varies by model specification\n")
cat("   - DCC provides explicit correlation parameters (α, β)\n")
cat("   - CGARCH separates marginal and dependence modeling\n")
cat("   - GOGARCH uses factor structure for dimension reduction\n")
cat("\n")
cat("3. UNCERTAINTY: Bootstrap analysis reveals substantial weight uncertainty\n")
cat("   - 95% CIs can span 20-40 percentage points\n")
cat("   - Optimal weights are estimates, not certainties\n")
cat("\n")
cat("4. ROBUSTNESS: Strategies with regularization (Shrinkage, Risk Parity)\n")
cat("   often outperform unconstrained optimization out-of-sample\n")
cat("\n")
cat("5. IMPLICATIONS:\n")
cat("   - Use bootstrap CIs to assess allocation confidence\n")
cat("   - Compare results across model types for robustness\n")
cat("   - Consider robust/regularized methods over naive optimization\n")
cat("   - Report uncertainty alongside point estimates\n")
```

# Part 14: Comparing Bootstrap Methods

In the previous sections, we compared different multivariate GARCH specifications (DCC, CGARCH, GOGARCH) within the MS-VARMA-GARCH bootstrap framework. Now we step back to compare **different bootstrap methods** themselves.

## The Bootstrap Averaging Approach

In classical portfolio optimization, we compute weights from a single optimization on the sample covariance matrix. This gives us a point estimate, but no sense of how uncertain that estimate is.

With bootstrap methods, we can instead:

1. Generate many resampled versions of our return series
2. Compute optimal weights on each resampled series
3. Average the resulting weights across all bootstrap replicates

This **bootstrap-averaged** portfolio has two advantages:

- It quantifies uncertainty (via the distribution of weights)
- The averaged weights may be more robust than the single-sample optimum

## Bootstrap Methods Compared

We compare six bootstrap approaches, ranging from simple to sophisticated:

| Method | Description |
|--------|-------------|
| **Plain (iid)** | Resample individual observations (ignores time structure) |
| **Moving Block** | Resample contiguous blocks of 5 days |
| **Stationary Block** | Random block lengths (geometric distribution) |
| **HMM** | Hidden Markov Model regime-based resampling |
| **MS-VARMA-GARCH** | Full Markov-Switching GARCH with DCC correlation |
| **Wild** | Multiply returns by random signs (preserves heteroskedasticity) |

The simpler methods (Plain, Moving, Stationary) are fast but ignore complex dependence structures. The model-based methods (HMM, MS-VARMA-GARCH) capture regime dynamics but require more computation. Wild bootstrap is designed for heteroskedastic data.

```{r bootstrap_comparison_header, echo=FALSE}
cat("\n")
cat("=", rep("=", 70), "\n", sep = "")
cat("BOOTSTRAP METHOD COMPARISON\n")
cat("=", rep("=", 70), "\n", sep = "")
```

```{r bootstrap_comparison_setup}
## Use first training window for comparison
y_compare <- y_full[1:train_window, ]

## Number of bootstrap replicates for comparison
num_boots_compare <- 30

## Point estimate (classical single-optimization)
point_weights <- risk_parity_portfolio(y_compare)
```

```{r bootstrap_comparison_run, message=FALSE, warning=FALSE}
## Storage for results
bootstrap_methods <- list()

## -------------------------------------------------------------------------
## 1. Plain (iid) Bootstrap - block_length = 1
## -------------------------------------------------------------------------
cat("Running Plain (iid) bootstrap...\n")
plain_result <- tryCatch({
  result <- tsbs(
    x = y_compare,
    bs_type = "moving",
    num_boots = num_boots_compare,
    block_length = 1,
    func = risk_parity_portfolio,
    apply_func_to = "all"
  )
  do.call(rbind, lapply(result$func_outs, as.vector))
}, error = function(e) {
  message("  Failed: ", e$message)
  NULL
})
if (!is.null(plain_result)) bootstrap_methods[["Plain (iid)"]] <- plain_result

## -------------------------------------------------------------------------
## 2. Moving Block Bootstrap - block_length = 5
## -------------------------------------------------------------------------
cat("Running Moving Block bootstrap...\n")
moving_result <- tryCatch({
  result <- tsbs(
    x = y_compare,
    bs_type = "moving",
    num_boots = num_boots_compare,
    block_length = 5,
    func = risk_parity_portfolio,
    apply_func_to = "all"
  )
  do.call(rbind, lapply(result$func_outs, as.vector))
}, error = function(e) {
  message("  Failed: ", e$message)
  NULL
})
if (!is.null(moving_result)) bootstrap_methods[["Moving Block"]] <- moving_result

## -------------------------------------------------------------------------
## 3. Stationary Block Bootstrap
## -------------------------------------------------------------------------
cat("Running Stationary Block bootstrap...\n")
stationary_result <- tryCatch({
  result <- tsbs(
    x = y_compare,
    bs_type = "stationary",
    num_boots = num_boots_compare,
    func = risk_parity_portfolio,
    apply_func_to = "all"
  )
  do.call(rbind, lapply(result$func_outs, as.vector))
}, error = function(e) {
  message("  Failed: ", e$message)
  NULL
})
if (!is.null(stationary_result)) bootstrap_methods[["Stationary"]] <- stationary_result

## -------------------------------------------------------------------------
## 4. HMM Bootstrap
## -------------------------------------------------------------------------
cat("Running HMM bootstrap...\n")
hmm_result <- tryCatch({
  result <- tsbs(
    x = y_compare,
    bs_type = "hmm",
    num_boots = num_boots_compare,
    num_states = 2,
    func = risk_parity_portfolio,
    apply_func_to = "all"
  )
  do.call(rbind, lapply(result$func_outs, as.vector))
}, error = function(e) {
  message("  Failed: ", e$message)
  NULL
})
if (!is.null(hmm_result)) bootstrap_methods[["HMM"]] <- hmm_result

## -------------------------------------------------------------------------
## 5. MS-VARMA-GARCH Bootstrap (DCC)
## -------------------------------------------------------------------------
cat("Running MS-VARMA-GARCH bootstrap...\n")
msgarch_result <- tryCatch({
  result <- tsbs(
    x = y_compare,
    bs_type = "ms_varma_garch",
    num_boots = num_boots_compare,
    num_blocks = 15,
    num_states = 2,
    spec = spec_dcc,  ## Use DCC for stability
    model_type = "multivariate",
    func = risk_parity_portfolio,
    apply_func_to = "all",
    control = list(max_iter = max_iter, tol = 1e-2)
  )
  do.call(rbind, lapply(result$func_outs, as.vector))
}, error = function(e) {
  message("  Failed: ", e$message)
  NULL
})
if (!is.null(msgarch_result)) bootstrap_methods[["MS-VARMA-GARCH"]] <- msgarch_result

## -------------------------------------------------------------------------
## 6. Wild Bootstrap
## -------------------------------------------------------------------------
cat("Running Wild bootstrap...\n")
wild_result <- tryCatch({
  result <- tsbs(
    x = y_compare,
    bs_type = "wild",
    num_boots = num_boots_compare,
    func = risk_parity_portfolio,
    apply_func_to = "all"
  )
  do.call(rbind, lapply(result$func_outs, as.vector))
}, error = function(e) {
  message("  Failed: ", e$message)
  NULL
})
if (!is.null(wild_result)) bootstrap_methods[["Wild"]] <- wild_result

cat("\nCompleted", length(bootstrap_methods), "of 6 bootstrap methods.\n")
```

```{r bootstrap_comparison_table, echo=FALSE}
## Build comparison table
if (length(bootstrap_methods) > 0) {
  
  cat("\n")
  cat("-", rep("-", 70), "\n", sep = "")
  cat("BOOTSTRAP-AVERAGED WEIGHTS COMPARISON\n")
  cat("-", rep("-", 70), "\n", sep = "")
  
  ## Create summary table
  summary_list <- lapply(names(bootstrap_methods), function(method) {
    boot_mat <- bootstrap_methods[[method]]
    colnames(boot_mat) <- symbols
    
    data.frame(
      Method = method,
      Asset = symbols,
      Point = round(point_weights, 3),
      Boot_Mean = round(colMeans(boot_mat), 3),
      Boot_SD = round(apply(boot_mat, 2, sd), 3),
      CI_Width = round(apply(boot_mat, 2, function(x) diff(quantile(x, c(0.025, 0.975)))), 3)
    )
  })
  
  summary_df <- do.call(rbind, summary_list)
  
  ## Print summary for each method
  cat("\nPoint estimate vs. bootstrap-averaged weights by method:\n")
  cat("(Point = single optimization, Boot_Mean = average of", num_boots_compare, "optimizations)\n\n")
  
  for (method in unique(summary_df$Method)) {
    cat("---", method, "---\n")
    method_df <- summary_df[summary_df$Method == method, c("Asset", "Point", "Boot_Mean", "Boot_SD", "CI_Width")]
    print(method_df, row.names = FALSE)
    cat("\n")
  }
  
  ## Cross-method comparison of mean weights
  cat("-", rep("-", 70), "\n", sep = "")
  cat("CROSS-METHOD COMPARISON (Bootstrap Mean Weights)\n")
  cat("-", rep("-", 70), "\n", sep = "")
  
  cross_compare <- data.frame(Asset = symbols, Point = round(point_weights, 3))
  for (method in names(bootstrap_methods)) {
    boot_mat <- bootstrap_methods[[method]]
    cross_compare[[method]] <- round(colMeans(boot_mat), 3)
  }
  cat("\n")
  print(cross_compare, row.names = FALSE)
  
  ## Summary statistics
  cat("\n")
  cat("-", rep("-", 70), "\n", sep = "")
  cat("UNCERTAINTY BY METHOD (Mean 95% CI Width)\n")
  cat("-", rep("-", 70), "\n", sep = "")
  cat("\n")
  
  uncertainty_summary <- sapply(names(bootstrap_methods), function(method) {
    boot_mat <- bootstrap_methods[[method]]
    mean(apply(boot_mat, 2, function(x) diff(quantile(x, c(0.025, 0.975)))))
  })
  
  uncertainty_df <- data.frame(
    Method = names(uncertainty_summary),
    Mean_CI_Width = round(uncertainty_summary, 4)
  )
  uncertainty_df <- uncertainty_df[order(uncertainty_df$Mean_CI_Width), ]
  print(uncertainty_df, row.names = FALSE)
}
```

```{r bootstrap_comparison_plot, fig.width=12, fig.height=8}
## Visualization: Weight distributions across all bootstrap methods
if (length(bootstrap_methods) >= 2) {
  
  ## Prepare data for plotting
  plot_list <- lapply(names(bootstrap_methods), function(method) {
    boot_mat <- bootstrap_methods[[method]]
    data.frame(
      Weight = as.vector(boot_mat),
      Asset = rep(symbols, each = nrow(boot_mat)),
      Method = method
    )
  })
  
  plot_df <- do.call(rbind, plot_list)
  
  ## Set method order (simple to complex)
  method_order <- c("Plain (iid)", "Moving Block", "Stationary", "Wild", "HMM", "MS-VARMA-GARCH")
  method_order <- method_order[method_order %in% names(bootstrap_methods)]
  plot_df$Method <- factor(plot_df$Method, levels = method_order)
  
  ## Add point estimate reference
  point_df <- data.frame(
    Asset = symbols,
    Point = point_weights
  )
  
  ## Create plot
  p <- ggplot(plot_df, aes(x = Method, y = Weight, fill = Method)) +
    geom_boxplot(alpha = 0.7, outlier.size = 0.5) +
    geom_hline(data = point_df, aes(yintercept = Point), 
               linetype = "dashed", color = "red", linewidth = 0.5) +
    facet_wrap(~ Asset, scales = "free_y", nrow = 1) +
    scale_fill_brewer(palette = "Set2") +
    labs(
      title = "Portfolio Weight Distributions by Bootstrap Method",
      subtitle = "Red dashed line = point estimate (single optimization). Boxes = distribution across bootstrap replicates.",
      x = NULL,
      y = "Weight"
    ) +
    theme_minimal() +
    theme(
      legend.position = "none",
      axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
      strip.text = element_text(face = "bold"),
      plot.title = element_text(face = "bold")
    )
  
  print(p)
}
```

```{r bootstrap_comparison_interpretation, echo=FALSE}
if (length(bootstrap_methods) >= 2) {
  cat("\n")
  cat("-", rep("-", 70), "\n", sep = "")
  cat("INTERPRETATION\n")
  cat("-", rep("-", 70), "\n", sep = "")
  cat("\n")
  cat("Key observations:\n\n")
  cat("1. POINT vs BOOTSTRAP MEAN: The bootstrap-averaged weights generally differ\n")
  cat("   from the point estimate, sometimes substantially. This reflects estimation\n")
  cat("   uncertainty that the single-sample optimum ignores.\n\n")
  cat("2. METHOD AGREEMENT: If different bootstrap methods produce similar averaged\n")
  cat("   weights, this suggests the result is robust. Large disagreements indicate\n")
  cat("   sensitivity to assumptions about the data-generating process.\n\n")
  cat("3. UNCERTAINTY LEVELS: Simpler methods (Plain, Moving) often show different\n")
  cat("   uncertainty than model-based methods (HMM, MS-VARMA-GARCH). Neither is\n")
  cat("   'correct' - they reflect different assumptions about dependence structure.\n\n")
  cat("4. PRACTICAL GUIDANCE:\n")
  cat("   - For quick robustness checks: use Moving or Stationary block bootstrap\n")
  cat("   - For regime-aware analysis: use HMM or MS-VARMA-GARCH\n")
  cat("   - For heteroskedasticity: Wild bootstrap preserves variance patterns\n")
  cat("   - Report results from multiple methods when possible\n")
}
```

## Runtime Benchmark

Different bootstrap methods have vastly different computational costs. The simpler block-based methods are fast, while model-based methods (HMM, MS-VARMA-GARCH) require fitting complex models and are correspondingly slower.

The `benchmark_tsbs()` utility allows systematic comparison of runtime across methods as we vary parameters like the number of bootstrap replicates. This helps in choosing an appropriate method given time constraints.

Note that the MS VARMA GARCH Bootstrap is very much slower than any of the other bootstrap methods.

```{r benchmark_header, echo=FALSE}
cat("\n")
cat("-", rep("-", 70), "\n", sep = "")
cat("RUNTIME BENCHMARK\n")
cat("-", rep("-", 70), "\n", sep = "")
```

```{r benchmark_run, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
## Define setups to benchmark (excluding slow MS-VARMA-GARCH for quick demo)
benchmark_setups <- list(
  "Plain (iid)" = list(bs_type = "moving", block_length = 1),
  "Moving Block" = list(bs_type = "moving", block_length = 5),
  "Stationary" = list(bs_type = "stationary"),
  "HMM" = list(bs_type = "hmm", num_states = 2),
  "Wild" = list(bs_type = "wild")
)

## Add HMM only for full analysis (it's moderately slow)
if (FULL_ANALYSIS) {
  ## Note: We don't pass 'func' - we're measuring bootstrap generation time only
  benchmark_setups[["MSGARCH"]] <-  list(
    bs_type = "ms_varma_garch", 
    model_type = "multivariate",
    num_states = 2,
    spec = spec_dcc,
    control = list(max_iter = 3)
  )
}

## Values to test: number of bootstrap replicates
#benchmark_values <- c(10, 25, 50)
benchmark_values <- 2^(3:9)
if (FULL_ANALYSIS) {
  benchmark_values <- 2^(2:5)
}

cat("Benchmarking", length(benchmark_setups), "methods across", 
    length(benchmark_values), "replicate counts...\n\n")

## Run benchmark
bench_result <- tryCatch({
  benchmark_tsbs(
    x = y_compare,
    setups = benchmark_setups,
    vary = "num_boots",
    values = benchmark_values,
    times = 3,
    verbose = TRUE
  )
}, error = function(e) {
  message("Benchmark failed: ", e$message)
  NULL
})

## Display results
if (!is.null(bench_result)) {
  cat("\n")
  print(bench_result)
  
  ## Plot
  plot(bench_result, show_ribbon = FALSE, show_points = TRUE)
}
```

```{r benchmark_run_nboot, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
## Define setups to benchmark (excluding slow MS-VARMA-GARCH for quick demo)
benchmark_setups <- list(
  "Plain (iid)" = list(bs_type = "moving", block_length = 1),
  "Moving Block" = list(bs_type = "moving", block_length = 5),
  "Stationary" = list(bs_type = "stationary"),
  "HMM" = list(bs_type = "hmm", num_states = 2),
  "Wild" = list(bs_type = "wild")
)

## Add HMM only for full analysis (it's moderately slow)
if (FULL_ANALYSIS) {
  ## Note: We don't pass 'func' - we're measuring bootstrap generation time only
  benchmark_setups[["MSGARCH"]] <-  list(
    bs_type = "ms_varma_garch", 
    model_type = "multivariate",
    num_states = 2,
    spec = spec_dcc,
    control = list(max_iter = 3)
  )
}

## Values to test: number of bootstrap replicates
#benchmark_values <- c(10, 25, 50)
benchmark_values <- 2^(6:10)
if (FULL_ANALYSIS) {
  benchmark_values <- 2^(6:9)
}

cat("Benchmarking", length(benchmark_setups), "methods across", 
    length(benchmark_values), "replicate counts...\n\n")

## Run benchmark
bench_result <- tryCatch({
  benchmark_tsbs(
    x = y_compare,
    setups = benchmark_setups,
    vary = "n_boot",
    values = benchmark_values,
    times = 3,
    verbose = TRUE
  )
}, error = function(e) {
  message("Benchmark failed: ", e$message)
  NULL
})

## Display results
if (!is.null(bench_result)) {
  cat("\n")
  print(bench_result)
  
  ## Plot
  plot(bench_result, show_ribbon = FALSE, show_points = TRUE)
}
```

```{r benchmark_run_nassets, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
## Define setups to benchmark (excluding slow MS-VARMA-GARCH for quick demo)
benchmark_setups <- list(
  "Plain (iid)" = list(bs_type = "moving", block_length = 1),
  "Moving Block" = list(bs_type = "moving", block_length = 5),
  "Stationary" = list(bs_type = "stationary"),
  "HMM" = list(bs_type = "hmm", num_states = 2),
  "Wild" = list(bs_type = "wild")
)

## Add HMM only for full analysis (it's moderately slow)
if (FULL_ANALYSIS) {
  ## Note: We don't pass 'func' - we're measuring bootstrap generation time only
  benchmark_setups[["MSGARCH"]] <-  list(
    bs_type = "ms_varma_garch", 
    model_type = "multivariate",
    num_states = 2,
    spec = spec_dcc,
    control = list(max_iter = 3)
  )
}

## Values to test: number of bootstrap replicates
#benchmark_values <- c(10, 25, 50)
benchmark_values <- 2^(2:7)
if (FULL_ANALYSIS) {
  benchmark_values <- 2^(2:7)
}

cat("Benchmarking", length(benchmark_setups), "methods across", 
    length(benchmark_values), "replicate counts...\n\n")

## Run benchmark
bench_result <- tryCatch({
  benchmark_tsbs(
    x = matrix(rnorm((2^7) * 252), nrow = 252),#y_compare,
    setups = benchmark_setups,
    vary = "n_assets",
    values = benchmark_values,
    times = 3,
    verbose = TRUE
  )
}, error = function(e) {
  message("Benchmark failed: ", e$message)
  NULL
})

## Display results
if (!is.null(bench_result)) {
  cat("\n")
  print(bench_result)
  
  ## Plot
  plot(bench_result, show_ribbon = FALSE, show_points = TRUE)
}
```



```{r benchmark_interpretation, echo=FALSE}
if (!is.null(bench_result)) {
  cat("\n")
  cat("-", rep("-", 70), "\n", sep = "")
  cat("BENCHMARK INTERPRETATION\n")
  cat("-", rep("-", 70), "\n", sep = "")
  cat("\n")
  cat("Key takeaways:\n\n")
  cat("1. BLOCK METHODS ARE FAST: Plain, Moving Block, and Stationary bootstrap\n")
  cat("   have nearly identical runtime - the block structure adds minimal overhead.\n\n")
  cat("2. WILD BOOTSTRAP: Also very fast since it only multiplies by random signs.\n\n")
  cat("3. LINEAR SCALING: All methods scale roughly linearly with num_boots,\n")
  cat("   making it easy to estimate runtime for larger analyses.\n\n")
  cat("4. HMM/MS-VARMA-GARCH: Much slower due to model fitting. Use these when\
\n")
  cat("   regime dynamics are important, but be aware of the computational cost.\n\n")
  cat("5. PRACTICAL TIP: For exploratory analysis, start with fast methods.\n")
  cat("   Switch to model-based methods for final results when regime structure matters.\n")
}
```

# Conclusion

This vignette demonstrated:

1. **Multi-model comparison**: DCC, CGARCH, and GOGARCH each provide different perspectives on correlation dynamics and portfolio uncertainty.

2. **Bootstrap diagnostics**: The `tsbs` package's diagnostic system provides comprehensive insights into bootstrap quality and model behavior.

3. **Practical portfolio optimization**: Six strategies were compared using real market data with quarterly rebalancing.

4. **Uncertainty quantification**: Bootstrap methods reveal substantial uncertainty in optimal weights, which should inform allocation decisions.

5. **Bootstrap method comparison**: Different bootstrap approaches (block, HMM, MS-VARMA-GARCH, wild) produce different uncertainty estimates, reflecting their assumptions about the data-generating process.

For more details on the underlying models, see:
- `?tsbs` for the main bootstrap interface
- `?estimate_garch_weighted_dcc` for DCC estimation
- `?estimate_garch_weighted_cgarch` for CGARCH estimation  
- `?estimate_garch_weighted_gogarch` for GOGARCH estimation
- `?compute_bootstrap_diagnostics` for the diagnostics system

```{r session_info, echo=FALSE}
cat("\n")
cat("=", rep("=", 70), "\n", sep = "")
cat("SESSION INFO\n")
cat("=", rep("=", 70), "\n", sep = "")
cat("\nVignette completed at:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n")
cat("R version:", R.version.string, "\n")
```