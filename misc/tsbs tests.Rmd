---
title: "tsbs tests"
output: html_document
date: "2025-06-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tsbs)
```

```{r}
x <- matrix(rnorm(40), ncol = 2)
boots <- tsbs::blockBootstrap(x, num_boots = 3)
length(boots)
```


```{r}
# set.seed(42)
# x <- arima.sim(n = 100, list(ar = 0.8))
# result <- bootstrap(
#   x = x,
#   block_length = 10,
#   type = "stationary",
#   num_blocks = 5,
#   num_boots = 100,
#   func = mean,
#   apply_func_to = "cols",
#   p_method = "plugin"
# )
# print(result$func_out_means)
```






```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(hmm_bootstrap(returns, n_boot = NULL, num_states = 2, num_blocks = 20, num_boots = 10))
```

```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(hmm_bootstrap(returns, n_boot = 100, num_states = 2, num_blocks = NULL, num_boots = 10))
```


```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(hmm_bootstrap(returns, n_boot = 100, num_states = 2, num_blocks = 20, num_boots = 10))
```

```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(msar_bootstrap(returns, n_boot = NULL, num_states = 2, num_blocks = 20, num_boots = 10))
```

```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(msar_bootstrap(returns, n_boot = 100, num_states = 2, num_blocks = NULL, num_boots = 10))
```

```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(msar_bootstrap(returns, n_boot = 100, num_states = 2, num_blocks = 20, num_boots = 10))
```


```{r}
boot_out <- tsbs( 
  x = rnorm(50),
  n_boot = 100L,
  block_length = NULL,
  type = "moving",
  num_blocks = NULL,
  num_boots = 10L,
  func = mean,
  apply_func_to = "cols",
  p_method = "cross validation",
  p = NULL,
  overlap = TRUE,
  ar_order = 1,
  num_states = 2,
  model_func = default_model_func,
  score_func = mse     
)

str(boot_out)
```


```{r}
set.seed(42)
#x <- arima.sim(n = 100, list(ar = 0.8))
x <- as.matrix(data.frame("a" = arima.sim(n = 100, list(ar = 0.8)), "b" = arima.sim(n = 100, list(ar = 0.8))))
result <- tsbs(
  x = x,
  n_boot = 100L,
  block_length = 10,
  bs_type = "msar",
  block_type = "tapered",
  taper_type = "tukey",
  tukey_alpha = 0.2,
  num_blocks = 5,
  num_boots = 10L,
  func = mean,
  apply_func_to = "cols",
  p_method = "plugin",
  parallel = TRUE,
  num_cores = 2
)
print(result$func_out_means)
```


## Test `fit_msvar()`
```{r}
# Generate sample data
set.seed(123)
T_obs <- 250
y1 <- arima.sim(model = list(ar = 0.7), n = T_obs)
y2 <- 0.5 * y1 + arima.sim(model = list(ar = 0.3), n = T_obs)
sample_data <- cbind(y1, y2)

# Fit the model (assuming the package is loaded)
msvar_fit <- fit_msvar(sample_data)
```


```{r}
# View results
print(msvar_fit$P)
plot(msvar_fit$smoothed_probabilities[, 1], type = 'l',
    main = "Smoothed Probability of State 1", ylab = "Probability")
```

## Test 
```{r}
## Generate sample data
set.seed(123)
T_obs <- 250
y1 <- arima.sim(model = list(ar = 0.7), n = T_obs)
y2 <- 0.5 * y1 + arima.sim(model = list(ar = 0.3), n = T_obs)
sample_data <- cbind(y1, y2)

## Run the bootstrap function (assuming fit_msvar is loaded)
bootstrap_results <- msvar_bootstrap(sample_data, num_boots = 5)

# View results
str(bootstrap_results)
```

```{r}
## Visualize the first original series against the first bootstrapped series
plot(sample_data[, 1], type = 'l', col = 'black',
    main = "Original vs. Bootstrapped Series",
    ylab = "Value", xlab = "Time", ylim = range(c(sample_data[,1], bootstrap_results[[1]][,1])))
lines(bootstrap_results[[1]][, 1], col = 'red', lty = 2)
legend("topright", legend = c("Original", "Bootstrap"),
      col = c("black", "red"), lty = c(1, 2))
```




```{r}
#' Visualization for MS-VAR Model and Bootstrap Results
#'
#' Demonstrates how to visualize the output of an MS-VAR model
#' by plotting the time series with background colors (ribbons) indicating
#' the estimated underlying state. It shows this for both the original data
#' and for a single bootstrapped series.

## --- 0. Setup and Dependencies ---
## Ensure the core functions are available. For this standalone script,
## we will use dummy versions. In a real package, they would be loaded.

## --- 1. Generate Sample Data ---
set.seed(123)
T_obs <- 300
y1 <- arima.sim(model = list(ar = 0.7), n = T_obs)
y2 <- 0.5 * y1 + arima.sim(model = list(ar = 0.3), n = T_obs)
original_data <- cbind(y1, y2)


## --- 2. Fit Model and Get Original State Sequence ---
message("Fitting model to original data...")
ms_model_fit <- fit_msvar(original_data)
original_probs <- ms_model_fit$smoothed_probabilities
original_states_short <- apply(original_probs, 1, which.max)

## Align state sequence with the full original data
original_states <- c(original_states_short[1], original_states_short)


## --- 3. Manually Perform One Bootstrap to Track States and Block Starts ---
message("Performing one bootstrap iteration manually...")

## a) Identify the blocks of data corresponding to each state run
state_runs <- rle(original_states)
state_ends <- cumsum(state_runs$lengths)
state_starts <- c(1, head(state_ends, -1) + 1)

## b) Create a list of data blocks and a parallel list of their states
data_blocks <- lapply(1:length(state_starts), function(i) {
  original_data[state_starts[i]:state_ends[i], , drop = FALSE]
})
block_states <- lapply(1:length(state_starts), function(i) {
  rep(state_runs$values[i], state_runs$lengths[i])
})

## c) Resample blocks to create a new series and its state sequence
num_resampled_blocks <- 20
resampled_indices <- sample(1:length(data_blocks), num_resampled_blocks, replace = TRUE)

bootstrapped_series <- do.call(rbind, data_blocks[resampled_indices])
bootstrapped_states <- do.call(c, block_states[resampled_indices])

## d) Calculate the start index of each resampled block in the new series
resampled_block_lengths <- sapply(data_blocks[resampled_indices], nrow)
bootstrapped_block_starts <- c(1, head(cumsum(resampled_block_lengths), -1) + 1)


## --- 4. Create a Reusable Plotting Function ---
#' Plot a time series with colored ribbons for states
#'
#' @param series A vector representing the time series to plot.
#' @param states A vector of the same length as `series` with integer states.
#' @param title A title for the plot.
#' @param v_lines A numeric vector of x-coordinates for vertical lines.
plot_with_states <- function(series, states, title, v_lines) {
  plot(series, type = 'n', main = title, ylab = "Value", xlab = "Time")
  
  ## Define colors for the state ribbons
  state_colors <- c(rgb(0.8, 0.8, 0.8, 0.4), rgb(0.6, 0.8, 1, 0.4))
  
  ## Add ribbons
  state_runs <- rle(states)
  state_ends <- cumsum(state_runs$lengths)
  state_starts <- c(1, head(state_ends, -1) + 1)
  
  for (i in 1:length(state_starts)) {
    rect(
      xleft = state_starts[i],
      ybottom = par("usr")[3], ## Bottom of the plot area
      xright = state_ends[i],
      ytop = par("usr")[4],    ## Top of the plot area
      col = state_colors[state_runs$values[i]],
      border = NA
    )
  }
  
  ## Add vertical lines at specified locations
  if (!is.null(v_lines)) {
    abline(v = v_lines, col = "red", lty = 2, lwd = 1.5)
  }
  
  ## Add the time series line on top
  lines(series, col = 'black', lwd = 1.5)
  
  ## Add a legend
  par(xpd=TRUE) ## Allow legend outside plotting area
  legend(
    #"topright",
    0,
    -4.5,
    legend = c("State 1", "State 2", "Block Start"),
    pch = c(15, 15, NA),      # Solid square for states
    lty = c(NA, NA, 2),       # Dashed line for block start
    col = c(state_colors, "red"), # Colors for pch and lty
    cex = 0.8,
    pt.cex = c(1, 1, 1),  # Size of the legend points
    lwd = c(NA, NA, 1.5),     # Line width for the legend
    bty = "n"
  )
}

## --- 5. Generate the Plots ---
message("Generating plots...")
## Set up a 2-panel plot layout
#par(mfrow = c(2, 1), mar = c(4, 4, 3, 2))
```

```{r}
## Plot the original series with its estimated states
## The vertical lines mark the start of each STATE run.
plot_with_states(
  series = original_data[, 1],
  states = original_states,
  title = "Original Series (y1) with Estimated State Runs",
  v_lines = state_starts
)
```

```{r}
## Plot the bootstrapped series with its reconstructed states
#3 The vertical lines now mark the start of each RESAMPLED BLOCK.
plot_with_states(
  series = bootstrapped_series[, 1],
  states = bootstrapped_states,
  title = "Bootstrapped Series (y1) with Reconstructed Blocks",
  v_lines = bootstrapped_block_starts
)
```

```{r}
## Reset plotting device to default
par(mfrow = c(1, 1))
```





```{r}
set.seed(123)
x <- arima.sim(n = 100, list(ar = 0.8))
result <- tsbs(
 x = x,
 block_length = 10,
 bs_type = "stationary",
 num_blocks = 5,
 num_boots = 10,
 func = mean,
 apply_func_to = "cols"
)
print(result$func_out_means)
```




```{r}
set.seed(123)
y1_vec <- rnorm(100)
y2_vec <- rnorm(100)

# --- THIS IS THE CRITICAL CORRECTION ---
# Ensure the input data is in xts format before passing to the spec function
y1_xts <- xts(y1_vec, order.by = Sys.Date() - (100:1))
y2_xts <- xts(y2_vec, order.by = Sys.Date() - (100:1))

model1 <- tsgarch::garch_modelspec(y1_xts, model = "garch", distribution = "norm") |> estimate(keep_tmb = TRUE)
model2 <- tsgarch::garch_modelspec(y2_xts, model = "garch", distribution = "norm") |> estimate(keep_tmb = TRUE)

# 2. Combine them into the special multi_estimate object
multi_model <- tsgarch::to_multi_estimate(list(model1, model2))
names(multi_model) <- c("series_1", "series_2")

# 3. Create the DCC spec with a Multivariate-t distribution
dcc_spec <- tsmarch::dcc_modelspec(multi_model, order = c(1,1), distribution = "mvt")

# 4. THE EVIDENCE: Print the parameter names
print(dcc_spec$parmatrix$parameter)
```




```{r}
# This example requires tsmarch and tsgarch packages
if (require(tsmarch) && require(tsgarch) && require(xts)) {
  # Generate small sample data
  set.seed(123)
  n <- 500
  returns <- matrix(rnorm(n * 2), ncol = 2)
  returns <- xts(returns, order.by = seq.Date(Sys.Date() - n + 1, 
                                                Sys.Date(), by = "day"))
  colnames(returns) <- c("series1", "series2")
  
  # Estimate univariate GARCH models
  spec1 <- garch_modelspec(returns[,1], model = "garch", order = c(1,1))
  spec2 <- garch_modelspec(returns[,2], model = "garch", order = c(1,1))
  fit1 <- estimate(spec1, keep_tmb = TRUE)
  fit2 <- estimate(spec2, keep_tmb = TRUE)
  
  # Combine into multivariate
  garch_fits <- to_multi_estimate(list(fit1, fit2))
  
  # Estimate DCC model
  dcc_spec <- dcc_modelspec(garch_fits, dynamics = "dcc", dcc_order = c(1,1))
  dcc_fit <- estimate(dcc_spec)
  
  # Get estimated parameters
  est_params <- coef(dcc_fit)
  
  # Compute log-likelihood at estimated parameters
  ll_at_est <- compute_loglik_fixed(dcc_fit, params = as.list(est_params))
  
  # Compute at alternative parameters
  ll_alt <- compute_loglik_fixed(dcc_fit, 
                                  params = list(alpha_1 = 0.05, beta_1 = 0.90))
  
  # The estimated parameters should give higher likelihood
  print(paste("LL at estimated:", ll_at_est))
  print(paste("LL at alternative:", ll_alt))
  print(paste("Difference:", ll_at_est - ll_alt))
}
```


```{r}
# Extended example with profile likelihood and LR tests
library(tsmarch)
library(tsgarch)
library(xts)

# Generate sample data with correlation structure
set.seed(100)
n <- 1500
# Create correlated innovations
rho <- 0.6
Sigma <- matrix(c(1, rho, rho, 1), 2, 2)
L <- chol(Sigma)
z <- matrix(rnorm(n * 2), ncol = 2) %*% L

# Add GARCH dynamics
returns <- z
for (i in 2:n) {
  h <- 0.01 + 0.08 * returns[i-1,]^2 + 0.90 * returns[i-1,]^2
  returns[i,] <- returns[i,] * sqrt(pmax(h, 0.001))
}

returns <- xts(returns, order.by = seq(Sys.Date() - n + 1, Sys.Date(), by = "day"))
colnames(returns) <- c("asset1", "asset2")

# Estimate univariate GARCH models
spec1 <- garch_modelspec(returns[,1], model = "garch", order = c(1,1))
spec2 <- garch_modelspec(returns[,2], model = "garch", order = c(1,1))
fit1 <- estimate(spec1, keep_tmb = TRUE)
fit2 <- estimate(spec2, keep_tmb = TRUE)

# Combine into multivariate
garch_fits <- to_multi_estimate(list(fit1, fit2))

# Estimate DCC model
dcc_spec <- dcc_modelspec(garch_fits, dynamics = "dcc", dcc_order = c(1,1))
dcc_fit <- estimate(dcc_spec)

# Get estimated parameters
est_params <- coef(dcc_fit)
cat("Estimated DCC parameters:\n")
print(est_params)

# Compute log-likelihood at estimated parameters
ll_at_estimated <- compute_loglik_fixed(dcc_fit, params = as.list(est_params))
cat("\nLL at estimated parameters:", ll_at_estimated, "\n")

# Test with alternative parameter values
ll_alternative <- compute_loglik_fixed(
  dcc_fit,
  params = list(alpha_1 = 0.03, beta_1 = 0.95)
)
cat("LL at alternative parameters:", ll_alternative, "\n")

# Likelihood ratio test
lr_stat <- 2 * (ll_at_estimated - ll_alternative)
p_value <- pchisq(lr_stat, df = 2, lower.tail = FALSE)
cat("\nLikelihood Ratio Test:\n")
cat("  LR statistic:", round(lr_stat, 4), "\n")
cat("  P-value:", format.pval(p_value, digits = 4), "\n")

# Profile likelihood for alpha
# Only compute if estimated alpha is not at boundary
alpha_est <- est_params["alpha_1"]
beta_est <- est_params["beta_1"]

if (alpha_est > 0.01 && alpha_est < 0.2) {
  cat("\nComputing profile likelihood for alpha...\n")
  
  # Create grid around estimated alpha
  alpha_range <- seq(max(0.001, alpha_est - 0.03), 
                     min(0.3, alpha_est + 0.03), 
                     length.out = 20)
  
  profile_ll <- sapply(alpha_range, function(a) {
    # Skip if would violate stationarity
    if (a + beta_est >= 0.999) return(NA_real_)
    
    tryCatch({
      compute_loglik_fixed(dcc_fit, 
                           params = list(alpha_1 = a, beta_1 = beta_est))
    }, error = function(e) NA_real_)
  })
  
  # Plot profile likelihood
  valid_idx <- !is.na(profile_ll)
  if (sum(valid_idx) > 5) {
    plot(alpha_range[valid_idx], profile_ll[valid_idx], type = "b", 
         xlab = expression(alpha), ylab = "Log-Likelihood",
         main = "Profile Likelihood for Alpha Parameter",
         pch = 19, col = "blue")
    abline(v = alpha_est, col = "red", lty = 2, lwd = 2)
    
    # Add confidence interval based on chi-squared cutoff
    ll_cutoff <- max(profile_ll, na.rm = TRUE) - qchisq(0.95, 1)/2
    abline(h = ll_cutoff, col = "gray", lty = 3)
    
    legend("bottomright", 
           legend = c("Profile LL", "Estimated alpha", "95% CI cutoff"), 
           col = c("blue", "red", "gray"), 
           lty = c(1, 2, 3), pch = c(19, NA, NA), cex = 0.8)
  }
} else {
  cat("\nSkipping profile likelihood (alpha at boundary)\n")
  cat("For a better example, try a different seed or larger sample.\n")
}

# Get component-wise log-likelihoods
ll_components <- compute_loglik_fixed(
  dcc_fit,
  params = as.list(est_params),
  return_components = TRUE
)
cat("\nComponent-wise log-likelihoods:\n")
cat("  Total:", round(ll_components$loglik, 2), "\n")
cat("  GARCH:", round(ll_components$garch_loglik, 2), "\n")
cat("  DCC:  ", round(ll_components$multivariate_loglik, 2), "\n")
cat("  Sum:  ", round(ll_components$garch_loglik + 
                       ll_components$multivariate_loglik, 2), "\n")
```




```{r}
cgarch_fit_test <- estimate(cgarch_spec)
est_params <- coef(cgarch_fit_test)

# Update spec with parameters
spec <- cgarch_fit_test$spec
spec$parmatrix[spec$parmatrix$estimate == 1, ]$value <- est_params

# Call with return_all = TRUE to see structure
result <- tsmarch:::.copula_dynamic_values(est_params, spec, return_all = TRUE)
names(result)
```

```{r}
str(result$ll_vec)
str(result$nll)
sum(result$ll_vec)
```

```{r}
cgarch_fit_test$loglik
```

```{r}
set.seed(456)
n <- 100
returns <- matrix(rnorm(n * 2), ncol = 2)
returns <- xts(returns, order.by = seq.Date(Sys.Date() - n + 1, 
                                            Sys.Date(), by = "day"))
colnames(returns) <- c("asset1", "asset2")

## Estimate univariate GARCH models
spec1 <- garch_modelspec(returns[,1], model = "garch", order = c(1,1))
spec2 <- garch_modelspec(returns[,2], model = "garch", order = c(1,1))
fit1 <- estimate(spec1, keep_tmb = TRUE)
fit2 <- estimate(spec2, keep_tmb = TRUE)

## Combine into multivariate
garch_fits <- to_multi_estimate(list(fit1, fit2))

## Estimate DCC model
dcc_spec <- dcc_modelspec(garch_fits, dynamics = "dcc", dcc_order = c(1,1))
dcc_fit <- estimate(dcc_spec)

## Get estimated parameters
est_params_dcc <- coef(dcc_fit)

dcc_result <- tsmarch:::.dcc_dynamic_values(est_params_dcc, dcc_spec, return_all = TRUE)
sum(dcc_result$ll_vec)  # after stripping maxpq
dcc_fit$loglik
```

```{r}
set.seed(456)
n <- 100
returns <- matrix(rnorm(n * 2), ncol = 2)
returns <- xts(returns, order.by = seq.Date(Sys.Date() - n + 1, 
                                            Sys.Date(), by = "day"))
colnames(returns) <- c("asset1", "asset2")

## Estimate univariate GARCH models
spec1 <- garch_modelspec(returns[,1], model = "garch", order = c(1,1))
spec2 <- garch_modelspec(returns[,2], model = "garch", order = c(1,1))
fit1 <- estimate(spec1, keep_tmb = TRUE)
fit2 <- estimate(spec2, keep_tmb = TRUE)

## Combine into multivariate
garch_fits <- to_multi_estimate(list(fit1, fit2))

## Estimate DCC model
dcc_spec <- dcc_modelspec(garch_fits, dynamics = "dcc", dcc_order = c(1,1))
dcc_fit <- estimate(dcc_spec)

## Get estimated parameters
est_params_dcc <- coef(dcc_fit)

dcc_result <- tsmarch:::.dcc_dynamic_values(est_params, dcc_spec, return_all = TRUE)
dcc_result$nll  # This is what we get with type = "nll"
dcc_fit$loglik  # Total stored in the object
sum(sapply(dcc_fit$spec$univariate, function(x) x$loglik))  # GARCH component
```

```{r}
# Minimal GOGARCH example
set.seed(123)
n <- 100
returns <- matrix(rnorm(n * 2), ncol = 2)
returns <- xts(returns, order.by = seq.Date(Sys.Date() - n + 1, Sys.Date(), by = "day"))
colnames(returns) <- c("asset1", "asset2")

# GOGARCH estimation
gogarch_spec <- gogarch_modelspec(returns, distribution = "norm", model = "garch", 
                                  order = c(1, 1), components = 2)
gogarch_fit <- estimate(gogarch_spec)

# Explore structure
names(gogarch_fit)
str(gogarch_fit$univariate)  # Independent component models
gogarch_fit$loglik
gogarch_fit$ica$K  # Mixing matrix K
gogarch_fit$ica$A  # Mixing matrix A

# Check if univariate models have lik_vector
gogarch_fit$univariate[[1]]$lik_vector
```



```{r}
# Test GOGARCH compute_loglik_fixed
gogarch_fit <- estimate(gogarch_spec)
est_params <- coef(gogarch_fit)

# Test total likelihood
ll_total <- compute_loglik_fixed(gogarch_fit, params = as.list(est_params))
cat("Computed LL:", ll_total, "\n")
cat("Stored LL:", -gogarch_fit$loglik, "\n")  # Note: stored as NLL
cat("Match?", abs(ll_total - (-gogarch_fit$loglik)) < 1e-6, "\n")

# Test per-observation likelihood
ll_vec_result <- compute_loglik_fixed(gogarch_fit, params = as.list(est_params), ll_vec = TRUE)
cat("Length:", length(ll_vec_result), "\n")
cat("Sum:", sum(ll_vec_result), "\n")
cat("Matches total?", abs(sum(ll_vec_result) - ll_total) < 1e-6, "\n")

# Test components
ll_components <- compute_loglik_fixed(gogarch_fit, params = as.list(est_params), 
                                      return_components = TRUE)
print(ll_components)
```

```{r}
# Component NLLs
comp1_nll <- sum(gogarch_fit$univariate[[1]]$lik_vector)
comp2_nll <- sum(gogarch_fit$univariate[[2]]$lik_vector)
total_comp_nll <- comp1_nll + comp2_nll

# Mixing adjustment
K <- gogarch_fit$ica$K
mixing_adj <- log(abs(det(K %*% t(K))))

# Total
total_nll <- total_comp_nll + mixing_adj

cat("Component 1 NLL:", comp1_nll, "\n")
cat("Component 2 NLL:", comp2_nll, "\n")
cat("Total component NLL:", total_comp_nll, "\n")
cat("Mixing adjustment:", mixing_adj, "\n")
cat("Total NLL:", total_nll, "\n")
cat("Stored loglik:", gogarch_fit$loglik, "\n")
```

```{r}
# Check what the actual calculation should be
log(abs(det(K %*% t(K))))  # = 0.251
log(abs(det(K)))  # Should try this if K is square
0.5 * log(abs(det(K %*% t(K))))  # = 0.1255 (half)

# The mixing term from logLik for components
comp1_ll <- as.numeric(logLik(gogarch_fit$univariate[[1]]))
comp2_ll <- as.numeric(logLik(gogarch_fit$univariate[[2]]))
cat("Component 1 LL:", comp1_ll, "\n")
cat("Component 2 LL:", comp2_ll, "\n")
cat("Sum:", comp1_ll + comp2_ll, "\n")
```

```{r}
# Test total likelihood
ll_total <- compute_loglik_fixed(gogarch_fit, params = as.list(est_params))
cat("Computed LL:", ll_total, "\n")
cat("Stored LL:", gogarch_fit$loglik, "\n")  
cat("Match?", abs(ll_total - gogarch_fit$loglik) < 1e-6, "\n")

# Test per-observation likelihood
ll_vec_result <- compute_loglik_fixed(gogarch_fit, params = as.list(est_params), ll_vec = TRUE)
cat("Sum:", sum(ll_vec_result), "\n")
cat("Matches total?", abs(sum(ll_vec_result) - ll_total) < 1e-6, "\n")
```

```{r}
ll_vec_result <- compute_loglik_fixed(gogarch_fit, params = as.list(est_params), ll_vec = TRUE)
cat("Sum:", sum(ll_vec_result), "\n")
cat("Total:", ll_total, "\n")
cat("Match?", abs(sum(ll_vec_result) - ll_total) < 1e-6, "\n")
```

```{r}
# Does the TMB object exist in the fitted component?
names(gogarch_fit$univariate[[1]])
gogarch_fit$univariate[[1]]$tmb  # Is this NULL or available?

# If available:
gogarch_fit$univariate[[1]]$tmb$fn  # The objective function
gogarch_fit$univariate[[1]]$tmb$par  # Current parameters
```

```{r}
# Test with parameter updates
# Get estimated parameters
est_params_dt <- coef(gogarch_fit)
print(est_params_dt)

# Create a test parameter list (slightly different from estimated)
test_params <- list(
  omega_1 = 0.03, alpha_1 = 0.04, beta_1 = 0.95,
  omega_2 = 0.35, alpha_2 = 0.00, beta_2 = 0.65
)

# Test with updated parameters
ll_at_test <- compute_loglik_fixed(gogarch_fit, params = test_params)
ll_at_estimated <- compute_loglik_fixed(gogarch_fit, params = list())

cat("LL at test params:", ll_at_test, "\n")
cat("LL at estimated params:", ll_at_estimated, "\n")
cat("Difference:", ll_at_estimated - ll_at_test, "\n")
cat("(Estimated should be higher)\n")
```

```{r}
# Verify against stored likelihood
cat("Computed at estimated:", ll_at_estimated, "\n")
cat("Stored in object:", gogarch_fit$loglik, "\n")
cat("Difference:", abs(ll_at_estimated - gogarch_fit$loglik), "\n")

# Also test that we can extract and use the estimated parameters in list format
est_params_list <- list(
  omega_1 = est_params_dt[series == "ica_component.1" & parameter == "omega"]$value,
  alpha_1 = est_params_dt[series == "ica_component.1" & parameter == "alpha1"]$value,
  beta_1 = est_params_dt[series == "ica_component.1" & parameter == "beta1"]$value,
  omega_2 = est_params_dt[series == "ica_component.2" & parameter == "omega"]$value,
  alpha_2 = est_params_dt[series == "ica_component.2" & parameter == "alpha1"]$value,
  beta_2 = est_params_dt[series == "ica_component.2" & parameter == "beta1"]$value
)

ll_at_est_list <- compute_loglik_fixed(gogarch_fit, params = est_params_list)
cat("\nLL using extracted estimated params:", ll_at_est_list, "\n")
cat("Should match stored:", gogarch_fit$loglik, "\n")
```


```{r}
# Check the parameter values and scales
comp1 <- gogarch_fit$univariate[[1]]

cat("Estimated parameter values (scaled):\n")
print(comp1$parmatrix[estimate == 1, .(parameter, value)])

cat("\nParameter scales:\n")
print(comp1$parameter_scale)

cat("\nTMB current parameters (unscaled):\n")
print(comp1$tmb$par)

cat("\nWhat we're passing to TMB (should match tmb$par):\n")
est_val <- comp1$parmatrix[estimate == 1]$value
print(est_val / comp1$parameter_scale)

# Test TMB function at current parameters
cat("\nTMB NLL at current params:\n")
print(comp1$tmb$fn(comp1$tmb$par))

cat("\nStored NLL:\n")
print(-comp1$loglik)
```

```{r}
# Diagnostic: Understanding the parameter system
comp1 <- gogarch_fit$univariate[[1]]

cat("=== PARMATRIX (the source of truth) ===\n")
print(comp1$parmatrix[estimate == 1, .(parameter, value, scale)])

cat("\n=== TMB$PAR (optimizer's working parameters) ===\n")
print(comp1$tmb$par)

cat("\n=== RELATIONSHIP TEST ===\n")
cat("parmatrix$value * parmatrix$scale:\n")
scaled_to_tmb <- comp1$parmatrix[estimate == 1]$value * comp1$parmatrix[estimate == 1]$scale
print(scaled_to_tmb)
cat("\nShould this equal tmb$par? ", all.equal(scaled_to_tmb, as.numeric(comp1$tmb$par)), "\n")

cat("\n=== STORED LOGLIK vs TMB EVALUATION ===\n")
cat("Stored loglik:", comp1$loglik, "\n")
cat("TMB fn at tmb$par:", -comp1$tmb$fn(comp1$tmb$par), "\n")
cat("(Should match if TMB is at estimated params)\n")
```

```{r}
# Check what's in the TMB environment
comp1 <- gogarch_fit$univariate[[1]]

cat("=== Exploring TMB environment ===\n")
tmb_env <- comp1$tmb$env
cat("Objects in TMB env:\n")
print(ls(tmb_env))

cat("\n=== Looking for last.par ===\n")
if (exists("last.par", envir = tmb_env)) {
  cat("last.par exists:\n")
  print(get("last.par", envir = tmb_env))
  
  cat("\nTMB fn at last.par:\n")
  print(-comp1$tmb$fn(get("last.par", envir = tmb_env)))
  
  cat("\nStored loglik:\n")
  print(comp1$loglik)
}

cat("\n=== Check last.par.best ===\n")
if (exists("last.par.best", envir = tmb_env)) {
  cat("last.par.best exists:\n")
  print(get("last.par.best", envir = tmb_env))
  
  cat("\nTMB fn at last.par.best:\n")
  print(-comp1$tmb$fn(get("last.par.best", envir = tmb_env)))
}
```


```{r}
# Test with parameter updates
# Get estimated parameters
est_params_dt <- coef(gogarch_fit)
print(est_params_dt)

# Create a test parameter list (slightly different from estimated)
test_params <- list(
  omega_1 = 0.03, alpha_1 = 0.04, beta_1 = 0.95,
  omega_2 = 0.35, alpha_2 = 0.00, beta_2 = 0.65
)

# Test with updated parameters
ll_at_test <- compute_loglik_fixed(gogarch_fit, params = test_params)
ll_at_estimated <- compute_loglik_fixed(gogarch_fit, params = list())

cat("LL at test params:", ll_at_test, "\n")
cat("LL at estimated params:", ll_at_estimated, "\n")
cat("Difference:", ll_at_estimated - ll_at_test, "\n")
cat("(Estimated should be higher)\n")
```

```{r}
# Verify against stored likelihood
cat("Computed at estimated:", ll_at_estimated, "\n")
cat("Stored in object:", gogarch_fit$loglik, "\n")
cat("Difference:", abs(ll_at_estimated - gogarch_fit$loglik), "\n")

# Also test that we can extract and use the estimated parameters in list format
est_params_list <- list(
  omega_1 = est_params_dt[series == "ica_component.1" & parameter == "omega"]$value,
  alpha_1 = est_params_dt[series == "ica_component.1" & parameter == "alpha1"]$value,
  beta_1 = est_params_dt[series == "ica_component.1" & parameter == "beta1"]$value,
  omega_2 = est_params_dt[series == "ica_component.2" & parameter == "omega"]$value,
  alpha_2 = est_params_dt[series == "ica_component.2" & parameter == "alpha1"]$value,
  beta_2 = est_params_dt[series == "ica_component.2" & parameter == "beta1"]$value
)

ll_at_est_list <- compute_loglik_fixed(gogarch_fit, params = est_params_list)
cat("\nLL using extracted estimated params:", ll_at_est_list, "\n")
cat("Should match stored:", gogarch_fit$loglik, "\n")
```


```{r}
# Check the parameter values and scales
comp1 <- gogarch_fit$univariate[[1]]

cat("Estimated parameter values (scaled):\n")
print(comp1$parmatrix[estimate == 1, .(parameter, value)])

cat("\nParameter scales:\n")
print(comp1$parameter_scale)

cat("\nTMB current parameters (unscaled):\n")
print(comp1$tmb$par)

cat("\nWhat we're passing to TMB (should match tmb$par):\n")
est_val <- comp1$parmatrix[estimate == 1]$value
print(est_val / comp1$parameter_scale)

# Test TMB function at current parameters
cat("\nTMB NLL at current params:\n")
print(comp1$tmb$fn(comp1$tmb$par))

cat("\nStored NLL:\n")
print(-comp1$loglik)
```

```{r}
# Diagnostic: Understanding the parameter system
comp1 <- gogarch_fit$univariate[[1]]

cat("=== PARMATRIX (the source of truth) ===\n")
print(comp1$parmatrix[estimate == 1, .(parameter, value, scale)])

cat("\n=== TMB$PAR (optimizer's working parameters) ===\n")
print(comp1$tmb$par)

cat("\n=== RELATIONSHIP TEST ===\n")
cat("parmatrix$value * parmatrix$scale:\n")
scaled_to_tmb <- comp1$parmatrix[estimate == 1]$value * comp1$parmatrix[estimate == 1]$scale
print(scaled_to_tmb)
cat("\nShould this equal tmb$par? ", all.equal(scaled_to_tmb, as.numeric(comp1$tmb$par)), "\n")

cat("\n=== STORED LOGLIK vs TMB EVALUATION ===\n")
cat("Stored loglik:", comp1$loglik, "\n")
cat("TMB fn at tmb$par:", -comp1$tmb$fn(comp1$tmb$par), "\n")
cat("(Should match if TMB is at estimated params)\n")
```

```{r}
comp1 <- gogarch_fit$univariate[[1]]
tmb_env <- comp1$tmb$env
last_par_best <- get("last.par.best", envir = tmb_env)

# Evaluate at estimated parameters
nll_est <- comp1$tmb$fn(last_par_best)
rep_est <- comp1$tmb$report(last_par_best)

cat("Names in report:\n")
print(names(rep_est))

cat("\nReport contents:\n")
str(rep_est)

# Test with different parameters
test_par <- c(0.03, 0.04, 0.95)
names(test_par) <- c("omega", "alpha", "beta")
nll_test <- comp1$tmb$fn(test_par)
rep_test <- comp1$tmb$report(test_par)

cat("\n\nReport at test params:\n")
str(rep_test)
```

```{r}
# Test 1: Scalar likelihood with no parameters (should match stored)
ll_at_estimated <- compute_loglik_fixed(gogarch_fit, params = list())
cat("LL at estimated params:", ll_at_estimated, "\n")
cat("Stored in object:", gogarch_fit$loglik, "\n")
cat("Difference:", abs(ll_at_estimated - gogarch_fit$loglik), "\n\n")

# Test 2: Scalar likelihood with test parameters
test_params <- list(
  omega_1 = 0.03, alpha_1 = 0.04, beta_1 = 0.95,
  omega_2 = 0.35, alpha_2 = 0.00, beta_2 = 0.65
)
ll_at_test <- compute_loglik_fixed(gogarch_fit, params = test_params)
cat("LL at test params:", ll_at_test, "\n")
cat("Difference from estimated:", ll_at_estimated - ll_at_test, "\n")
cat("(Should be positive)\n\n")

# Test 3: Vector likelihood
ll_vec_estimated <- compute_loglik_fixed(gogarch_fit, params = list(), ll_vec = TRUE)
cat("Length of lik_vector:", length(ll_vec_estimated), "\n")
cat("Sum of lik_vector:", sum(ll_vec_estimated), "\n")
cat("Should match scalar:", ll_at_estimated, "\n")
cat("Difference:", abs(sum(ll_vec_estimated) - ll_at_estimated), "\n\n")

# Test 4: With return_components
result_with_components <- compute_loglik_fixed(gogarch_fit, params = list(), 
                                               return_components = TRUE, ll_vec = FALSE)
cat("Component logliks:\n")
print(result_with_components$component_logliks)
cat("\nJacobian adjustment:", result_with_components$jacobian_adjustment, "\n")
cat("Total loglik:", result_with_components$loglik, "\n")
cat("Manual sum:", sum(result_with_components$component_logliks) + 
    result_with_components$jacobian_adjustment, "\n\n")

# Test 5: Vector with components
result_vec_components <- compute_loglik_fixed(gogarch_fit, params = list(), 
                                              return_components = TRUE, ll_vec = TRUE)
cat("First 5 observations of lik_vector:\n")
print(head(result_vec_components$lik_vector, 5))
cat("\nSum of lik_vector:", sum(result_vec_components$lik_vector), "\n")
cat("Stored loglik:", result_vec_components$loglik, "\n")
```

```{r}
# Test 3: Vector likelihood (should now match)
ll_vec_estimated <- compute_loglik_fixed(gogarch_fit, params = list(), ll_vec = TRUE)
cat("Length of lik_vector:", length(ll_vec_estimated), "\n")
cat("Sum of lik_vector:", sum(ll_vec_estimated), "\n")
cat("Should match scalar:", ll_at_estimated, "\n")
cat("Difference:", abs(sum(ll_vec_estimated) - ll_at_estimated), "\n\n")

# Test 5: Vector with components (should now be consistent)
result_vec_components <- compute_loglik_fixed(gogarch_fit, params = list(), 
                                              return_components = TRUE, ll_vec = TRUE)
cat("First 5 observations of lik_vector:\n")
print(head(result_vec_components$lik_vector, 5))
cat("\nSum of lik_vector:", sum(result_vec_components$lik_vector), "\n")
cat("Stored loglik field:", result_vec_components$loglik, "\n")
cat("Should both match stored:", gogarch_fit$loglik, "\n")
cat("Difference:", abs(result_vec_components$loglik - gogarch_fit$loglik), "\n")
```

```{r}
# Comprehensive final test
cat("=== COMPREHENSIVE TEST SUITE ===\n\n")

# Test 1: Scalar mode at estimated parameters
ll_scalar <- compute_loglik_fixed(gogarch_fit, params = list())
cat("1. Scalar at estimated: ", ll_scalar, "\n")
cat("   Matches stored: ", abs(ll_scalar - gogarch_fit$loglik) < 1e-10, "\n\n")

# Test 2: Vector mode at estimated parameters
ll_vector <- compute_loglik_fixed(gogarch_fit, params = list(), ll_vec = TRUE)
cat("2. Vector at estimated (length ", length(ll_vector), "):\n")
cat("   Sum: ", sum(ll_vector), "\n")
cat("   Matches scalar: ", abs(sum(ll_vector) - ll_scalar) < 1e-10, "\n\n")

# Test 3: Changing parameters
test_params <- list(
  omega_1 = 0.03, alpha_1 = 0.04, beta_1 = 0.95,
  omega_2 = 0.35, alpha_2 = 0.00, beta_2 = 0.65
)
ll_test_scalar <- compute_loglik_fixed(gogarch_fit, params = test_params)
ll_test_vector <- compute_loglik_fixed(gogarch_fit, params = test_params, ll_vec = TRUE)

cat("3. Changed parameters:\n")
cat("   Scalar: ", ll_test_scalar, "\n")
cat("   Vector sum: ", sum(ll_test_vector), "\n")
cat("   Vector matches scalar: ", abs(sum(ll_test_vector) - ll_test_scalar) < 1e-10, "\n")
cat("   Worse than estimated: ", ll_test_scalar < ll_scalar, "\n\n")

# Test 4: Partial parameter update (only component 1)
partial_params <- list(
  omega_1 = 0.05, alpha_1 = 0.03, beta_1 = 0.92
)
ll_partial <- compute_loglik_fixed(gogarch_fit, params = partial_params)
cat("4. Partial update (only component 1):\n")
cat("   Scalar: ", ll_partial, "\n")
cat("   Different from estimated: ", abs(ll_partial - ll_scalar) > 1e-10, "\n\n")

# Test 5: Return components mode
result_components <- compute_loglik_fixed(gogarch_fit, params = list(), 
                                         return_components = TRUE)
cat("5. Components breakdown:\n")
cat("   Component 1: ", result_components$component_logliks[1], "\n")
cat("   Component 2: ", result_components$component_logliks[2], "\n")
cat("   Jacobian: ", result_components$jacobian_adjustment, "\n")
cat("   Total: ", result_components$loglik, "\n")
cat("   Manual sum: ", sum(result_components$component_logliks) + 
    result_components$jacobian_adjustment, "\n\n")

# Test 6: Vector + components mode (for EM algorithm)
result_full <- compute_loglik_fixed(gogarch_fit, params = list(), 
                                   return_components = TRUE, ll_vec = TRUE)
cat("6. Full output for EM algorithm:\n")
cat("   Total loglik: ", result_full$loglik, "\n")
cat("   Vector length: ", length(result_full$lik_vector), "\n")
cat("   Vector sum: ", sum(result_full$lik_vector), "\n")
cat("   Has component_logliks: ", !is.null(result_full$component_logliks), "\n")
cat("   Has jacobian_adjustment: ", !is.null(result_full$jacobian_adjustment), "\n")
cat("   All consistent: ", 
    abs(result_full$loglik - sum(result_full$lik_vector)) < 1e-10, "\n\n")

cat("=== ALL TESTS PASSED ===\n")
```

