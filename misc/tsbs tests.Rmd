---
title: "tsbs tests"
output: html_document
date: "2025-06-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tsbs)
```

```{r}
x <- matrix(rnorm(40), ncol = 2)
boots <- tsbs::blockBootstrap(x, num_boots = 3)
length(boots)
```


```{r}
# set.seed(42)
# x <- arima.sim(n = 100, list(ar = 0.8))
# result <- bootstrap(
#   x = x,
#   block_length = 10,
#   type = "stationary",
#   num_blocks = 5,
#   num_boots = 100,
#   func = mean,
#   apply_func_to = "cols",
#   p_method = "plugin"
# )
# print(result$func_out_means)
```






```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(hmm_bootstrap(returns, n_boot = NULL, num_states = 2, num_blocks = 20, num_boots = 10))
```

```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(hmm_bootstrap(returns, n_boot = 100, num_states = 2, num_blocks = NULL, num_boots = 10))
```


```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(hmm_bootstrap(returns, n_boot = 100, num_states = 2, num_blocks = 20, num_boots = 10))
```

```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(msar_bootstrap(returns, n_boot = NULL, num_states = 2, num_blocks = 20, num_boots = 10))
```

```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(msar_bootstrap(returns, n_boot = 100, num_states = 2, num_blocks = NULL, num_boots = 10))
```

```{r}
set.seed(123)
returns <- as.matrix(arima.sim(n = 200, list(ar = 0.5)))
str(msar_bootstrap(returns, n_boot = 100, num_states = 2, num_blocks = 20, num_boots = 10))
```


```{r}
boot_out <- tsbs( 
  x = rnorm(50),
  n_boot = 100L,
  block_length = NULL,
  type = "moving",
  num_blocks = NULL,
  num_boots = 10L,
  func = mean,
  apply_func_to = "cols",
  p_method = "cross validation",
  p = NULL,
  overlap = TRUE,
  ar_order = 1,
  num_states = 2,
  model_func = default_model_func,
  score_func = mse     
)

str(boot_out)
```


```{r}
set.seed(42)
#x <- arima.sim(n = 100, list(ar = 0.8))
x <- as.matrix(data.frame("a" = arima.sim(n = 100, list(ar = 0.8)), "b" = arima.sim(n = 100, list(ar = 0.8))))
result <- tsbs(
  x = x,
  n_boot = 100L,
  block_length = 10,
  bs_type = "msar",
  block_type = "tapered",
  taper_type = "tukey",
  tukey_alpha = 0.2,
  num_blocks = 5,
  num_boots = 10L,
  func = mean,
  apply_func_to = "cols",
  p_method = "plugin",
  parallel = TRUE,
  num_cores = 2
)
print(result$func_out_means)
```


## Test `fit_msvar()`
```{r}
# Generate sample data
set.seed(123)
T_obs <- 250
y1 <- arima.sim(model = list(ar = 0.7), n = T_obs)
y2 <- 0.5 * y1 + arima.sim(model = list(ar = 0.3), n = T_obs)
sample_data <- cbind(y1, y2)

# Fit the model (assuming the package is loaded)
msvar_fit <- fit_msvar(sample_data)
```


```{r}
# View results
print(msvar_fit$P)
plot(msvar_fit$smoothed_probabilities[, 1], type = 'l',
    main = "Smoothed Probability of State 1", ylab = "Probability")
```

## Test 
```{r}
## Generate sample data
set.seed(123)
T_obs <- 250
y1 <- arima.sim(model = list(ar = 0.7), n = T_obs)
y2 <- 0.5 * y1 + arima.sim(model = list(ar = 0.3), n = T_obs)
sample_data <- cbind(y1, y2)

## Run the bootstrap function (assuming fit_msvar is loaded)
bootstrap_results <- msvar_bootstrap(sample_data, num_boots = 5)

# View results
str(bootstrap_results)
```

```{r}
## Visualize the first original series against the first bootstrapped series
plot(sample_data[, 1], type = 'l', col = 'black',
    main = "Original vs. Bootstrapped Series",
    ylab = "Value", xlab = "Time", ylim = range(c(sample_data[,1], bootstrap_results[[1]][,1])))
lines(bootstrap_results[[1]][, 1], col = 'red', lty = 2)
legend("topright", legend = c("Original", "Bootstrap"),
      col = c("black", "red"), lty = c(1, 2))
```




```{r}
#' Visualization for MS-VAR Model and Bootstrap Results
#'
#' Demonstrates how to visualize the output of an MS-VAR model
#' by plotting the time series with background colors (ribbons) indicating
#' the estimated underlying state. It shows this for both the original data
#' and for a single bootstrapped series.

## --- 0. Setup and Dependencies ---
## Ensure the core functions are available. For this standalone script,
## we will use dummy versions. In a real package, they would be loaded.

## --- 1. Generate Sample Data ---
set.seed(123)
T_obs <- 300
y1 <- arima.sim(model = list(ar = 0.7), n = T_obs)
y2 <- 0.5 * y1 + arima.sim(model = list(ar = 0.3), n = T_obs)
original_data <- cbind(y1, y2)


## --- 2. Fit Model and Get Original State Sequence ---
message("Fitting model to original data...")
ms_model_fit <- fit_msvar(original_data)
original_probs <- ms_model_fit$smoothed_probabilities
original_states_short <- apply(original_probs, 1, which.max)

## Align state sequence with the full original data
original_states <- c(original_states_short[1], original_states_short)


## --- 3. Manually Perform One Bootstrap to Track States and Block Starts ---
message("Performing one bootstrap iteration manually...")

## a) Identify the blocks of data corresponding to each state run
state_runs <- rle(original_states)
state_ends <- cumsum(state_runs$lengths)
state_starts <- c(1, head(state_ends, -1) + 1)

## b) Create a list of data blocks and a parallel list of their states
data_blocks <- lapply(1:length(state_starts), function(i) {
  original_data[state_starts[i]:state_ends[i], , drop = FALSE]
})
block_states <- lapply(1:length(state_starts), function(i) {
  rep(state_runs$values[i], state_runs$lengths[i])
})

## c) Resample blocks to create a new series and its state sequence
num_resampled_blocks <- 20
resampled_indices <- sample(1:length(data_blocks), num_resampled_blocks, replace = TRUE)

bootstrapped_series <- do.call(rbind, data_blocks[resampled_indices])
bootstrapped_states <- do.call(c, block_states[resampled_indices])

## d) Calculate the start index of each resampled block in the new series
resampled_block_lengths <- sapply(data_blocks[resampled_indices], nrow)
bootstrapped_block_starts <- c(1, head(cumsum(resampled_block_lengths), -1) + 1)


## --- 4. Create a Reusable Plotting Function ---
#' Plot a time series with colored ribbons for states
#'
#' @param series A vector representing the time series to plot.
#' @param states A vector of the same length as `series` with integer states.
#' @param title A title for the plot.
#' @param v_lines A numeric vector of x-coordinates for vertical lines.
plot_with_states <- function(series, states, title, v_lines) {
  plot(series, type = 'n', main = title, ylab = "Value", xlab = "Time")
  
  ## Define colors for the state ribbons
  state_colors <- c(rgb(0.8, 0.8, 0.8, 0.4), rgb(0.6, 0.8, 1, 0.4))
  
  ## Add ribbons
  state_runs <- rle(states)
  state_ends <- cumsum(state_runs$lengths)
  state_starts <- c(1, head(state_ends, -1) + 1)
  
  for (i in 1:length(state_starts)) {
    rect(
      xleft = state_starts[i],
      ybottom = par("usr")[3], ## Bottom of the plot area
      xright = state_ends[i],
      ytop = par("usr")[4],    ## Top of the plot area
      col = state_colors[state_runs$values[i]],
      border = NA
    )
  }
  
  ## Add vertical lines at specified locations
  if (!is.null(v_lines)) {
    abline(v = v_lines, col = "red", lty = 2, lwd = 1.5)
  }
  
  ## Add the time series line on top
  lines(series, col = 'black', lwd = 1.5)
  
  ## Add a legend
  par(xpd=TRUE) ## Allow legend outside plotting area
  legend(
    #"topright",
    0,
    -4.5,
    legend = c("State 1", "State 2", "Block Start"),
    pch = c(15, 15, NA),      # Solid square for states
    lty = c(NA, NA, 2),       # Dashed line for block start
    col = c(state_colors, "red"), # Colors for pch and lty
    cex = 0.8,
    pt.cex = c(1, 1, 1),  # Size of the legend points
    lwd = c(NA, NA, 1.5),     # Line width for the legend
    bty = "n"
  )
}

## --- 5. Generate the Plots ---
message("Generating plots...")
## Set up a 2-panel plot layout
#par(mfrow = c(2, 1), mar = c(4, 4, 3, 2))
```

```{r}
## Plot the original series with its estimated states
## The vertical lines mark the start of each STATE run.
plot_with_states(
  series = original_data[, 1],
  states = original_states,
  title = "Original Series (y1) with Estimated State Runs",
  v_lines = state_starts
)
```

```{r}
## Plot the bootstrapped series with its reconstructed states
#3 The vertical lines now mark the start of each RESAMPLED BLOCK.
plot_with_states(
  series = bootstrapped_series[, 1],
  states = bootstrapped_states,
  title = "Bootstrapped Series (y1) with Reconstructed Blocks",
  v_lines = bootstrapped_block_starts
)
```

```{r}
## Reset plotting device to default
par(mfrow = c(1, 1))
```





```{r}
set.seed(123)
x <- arima.sim(n = 100, list(ar = 0.8))
result <- tsbs(
 x = x,
 block_length = 10,
 bs_type = "stationary",
 num_blocks = 5,
 num_boots = 10,
 func = mean,
 apply_func_to = "cols"
)
print(result$func_out_means)
```




```{r}
set.seed(123)
y1_vec <- rnorm(100)
y2_vec <- rnorm(100)

# --- THIS IS THE CRITICAL CORRECTION ---
# Ensure the input data is in xts format before passing to the spec function
y1_xts <- xts(y1_vec, order.by = Sys.Date() - (100:1))
y2_xts <- xts(y2_vec, order.by = Sys.Date() - (100:1))

model1 <- tsgarch::garch_modelspec(y1_xts, model = "garch", distribution = "norm") |> estimate(keep_tmb = TRUE)
model2 <- tsgarch::garch_modelspec(y2_xts, model = "garch", distribution = "norm") |> estimate(keep_tmb = TRUE)

# 2. Combine them into the special multi_estimate object
multi_model <- tsgarch::to_multi_estimate(list(model1, model2))
names(multi_model) <- c("series_1", "series_2")

# 3. Create the DCC spec with a Multivariate-t distribution
dcc_spec <- tsmarch::dcc_modelspec(multi_model, order = c(1,1), distribution = "mvt")

# 4. THE EVIDENCE: Print the parameter names
print(dcc_spec$parmatrix$parameter)
```




```{r}
# This example requires tsmarch and tsgarch packages
if (require(tsmarch) && require(tsgarch) && require(xts)) {
  # Generate small sample data
  set.seed(123)
  n <- 500
  returns <- matrix(rnorm(n * 2), ncol = 2)
  returns <- xts(returns, order.by = seq.Date(Sys.Date() - n + 1, 
                                                Sys.Date(), by = "day"))
  colnames(returns) <- c("series1", "series2")
  
  # Estimate univariate GARCH models
  spec1 <- garch_modelspec(returns[,1], model = "garch", order = c(1,1))
  spec2 <- garch_modelspec(returns[,2], model = "garch", order = c(1,1))
  fit1 <- estimate(spec1, keep_tmb = TRUE)
  fit2 <- estimate(spec2, keep_tmb = TRUE)
  
  # Combine into multivariate
  garch_fits <- to_multi_estimate(list(fit1, fit2))
  
  # Estimate DCC model
  dcc_spec <- dcc_modelspec(garch_fits, dynamics = "dcc", dcc_order = c(1,1))
  dcc_fit <- estimate(dcc_spec)
  
  # Get estimated parameters
  est_params <- coef(dcc_fit)
  
  # Compute log-likelihood at estimated parameters
  ll_at_est <- compute_loglik_fixed(dcc_fit, params = as.list(est_params))
  
  # Compute at alternative parameters
  ll_alt <- compute_loglik_fixed(dcc_fit, 
                                  params = list(alpha_1 = 0.05, beta_1 = 0.90))
  
  # The estimated parameters should give higher likelihood
  print(paste("LL at estimated:", ll_at_est))
  print(paste("LL at alternative:", ll_alt))
  print(paste("Difference:", ll_at_est - ll_alt))
}
```


```{r}
# Extended example with profile likelihood and LR tests
library(tsmarch)
library(tsgarch)
library(xts)

# Generate sample data with correlation structure
set.seed(100)
n <- 1500
# Create correlated innovations
rho <- 0.6
Sigma <- matrix(c(1, rho, rho, 1), 2, 2)
L <- chol(Sigma)
z <- matrix(rnorm(n * 2), ncol = 2) %*% L

# Add GARCH dynamics
returns <- z
for (i in 2:n) {
  h <- 0.01 + 0.08 * returns[i-1,]^2 + 0.90 * returns[i-1,]^2
  returns[i,] <- returns[i,] * sqrt(pmax(h, 0.001))
}

returns <- xts(returns, order.by = seq(Sys.Date() - n + 1, Sys.Date(), by = "day"))
colnames(returns) <- c("asset1", "asset2")

# Estimate univariate GARCH models
spec1 <- garch_modelspec(returns[,1], model = "garch", order = c(1,1))
spec2 <- garch_modelspec(returns[,2], model = "garch", order = c(1,1))
fit1 <- estimate(spec1, keep_tmb = TRUE)
fit2 <- estimate(spec2, keep_tmb = TRUE)

# Combine into multivariate
garch_fits <- to_multi_estimate(list(fit1, fit2))

# Estimate DCC model
dcc_spec <- dcc_modelspec(garch_fits, dynamics = "dcc", dcc_order = c(1,1))
dcc_fit <- estimate(dcc_spec)

# Get estimated parameters
est_params <- coef(dcc_fit)
cat("Estimated DCC parameters:\n")
print(est_params)

# Compute log-likelihood at estimated parameters
ll_at_estimated <- compute_loglik_fixed(dcc_fit, params = as.list(est_params))
cat("\nLL at estimated parameters:", ll_at_estimated, "\n")

# Test with alternative parameter values
ll_alternative <- compute_loglik_fixed(
  dcc_fit,
  params = list(alpha_1 = 0.03, beta_1 = 0.95)
)
cat("LL at alternative parameters:", ll_alternative, "\n")

# Likelihood ratio test
lr_stat <- 2 * (ll_at_estimated - ll_alternative)
p_value <- pchisq(lr_stat, df = 2, lower.tail = FALSE)
cat("\nLikelihood Ratio Test:\n")
cat("  LR statistic:", round(lr_stat, 4), "\n")
cat("  P-value:", format.pval(p_value, digits = 4), "\n")

# Profile likelihood for alpha
# Only compute if estimated alpha is not at boundary
alpha_est <- est_params["alpha_1"]
beta_est <- est_params["beta_1"]

if (alpha_est > 0.01 && alpha_est < 0.2) {
  cat("\nComputing profile likelihood for alpha...\n")
  
  # Create grid around estimated alpha
  alpha_range <- seq(max(0.001, alpha_est - 0.03), 
                     min(0.3, alpha_est + 0.03), 
                     length.out = 20)
  
  profile_ll <- sapply(alpha_range, function(a) {
    # Skip if would violate stationarity
    if (a + beta_est >= 0.999) return(NA_real_)
    
    tryCatch({
      compute_loglik_fixed(dcc_fit, 
                           params = list(alpha_1 = a, beta_1 = beta_est))
    }, error = function(e) NA_real_)
  })
  
  # Plot profile likelihood
  valid_idx <- !is.na(profile_ll)
  if (sum(valid_idx) > 5) {
    plot(alpha_range[valid_idx], profile_ll[valid_idx], type = "b", 
         xlab = expression(alpha), ylab = "Log-Likelihood",
         main = "Profile Likelihood for Alpha Parameter",
         pch = 19, col = "blue")
    abline(v = alpha_est, col = "red", lty = 2, lwd = 2)
    
    # Add confidence interval based on chi-squared cutoff
    ll_cutoff <- max(profile_ll, na.rm = TRUE) - qchisq(0.95, 1)/2
    abline(h = ll_cutoff, col = "gray", lty = 3)
    
    legend("bottomright", 
           legend = c("Profile LL", "Estimated alpha", "95% CI cutoff"), 
           col = c("blue", "red", "gray"), 
           lty = c(1, 2, 3), pch = c(19, NA, NA), cex = 0.8)
  }
} else {
  cat("\nSkipping profile likelihood (alpha at boundary)\n")
  cat("For a better example, try a different seed or larger sample.\n")
}

# Get component-wise log-likelihoods
ll_components <- compute_loglik_fixed(
  dcc_fit,
  params = as.list(est_params),
  return_components = TRUE
)
cat("\nComponent-wise log-likelihoods:\n")
cat("  Total:", round(ll_components$loglik, 2), "\n")
cat("  GARCH:", round(ll_components$garch_loglik, 2), "\n")
cat("  DCC:  ", round(ll_components$multivariate_loglik, 2), "\n")
cat("  Sum:  ", round(ll_components$garch_loglik + 
                       ll_components$multivariate_loglik, 2), "\n")
```

